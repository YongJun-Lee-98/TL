가상머신이 활성화 되면서
완성된 가상 머신이 매우 무거워지고
네트워크를 통해 파일을 이동시키기 엄청 긴 시간이 소비되는데 이 상황에서
서비스 중단을 최소화할 수 있는 방법을 고민하는 것
downtime을 최소화하고 안정성을 높이기 위해
가상 머신 솔루션으로 스냅샷, 복구, 백업 등 전략들을 이용함
젠 프로젝트 및 VM웨어와 같은 소프트웨어는 이러한 문제를 경감시키는 일에 특화되어있음
클라우드 공급자들은 이러한 문제를 거의 제거하는 수준에 이름

오늘날에도 클라우드 제품에서 가상머신은 중요한 위치를 차지하고 있음
구글 클라우드는 가상 머신 서비스를 컴퓨트 엔진이라고 부름
이러한 가상 머신들은 머신러닝 작업의 성능 향상을 목적으로 강력한 GPU를 추가해 사용할 수 있도록 만들어져 있다는 점을 기억해두기

머신러닝 기술을 개발하고 배포하기 위한 컴퓨팅 환경을 구성하는 일에 있어서 가상 머신을 잘 활용하는 것만으로는 해결하기 어려운 부분들이 존재함
그래서 컨테이너 그리고 엣지 디바이스라는 주제가 있다는 사실을 미리 알고 있는 것이 좋음
가상 머신 기술은 스마트폰과 같은 엣지 디바이스를 호스트로 삼아 실행되기에는 어려움이 있음
가상 머신 기술은 컨테이너 기술과 달리 개발 과정에서 '언제, 어떤 환경에서 사용하든 상관없이 동일한 결과를 재현하기 위한 도구'로써 사용되기에는 너무 무겁고 느리다.

컨테이너 기술이나 엣지 디바이스 기술, 둘 중 어느 한 쪽을 반드시 사용할 필요는 없을지도 모름

당신이 이용할 수 있는 선택지들의 동작 방식을 이해하고 해결해야 하는 문제에 적절히 활용할 수 있다면 더 나은 머신러닝 엔지니어가 되는 데 도움이 될 것이라고 생각한다.

## 컨테이너
가상 머신의 장점을 갖추면서도 가상 머신이 무겁다는 문제를 상당부분 해결한 컨테이너 기술의 전반을 파악하는 것도 중요함

[레드헷 홈페이지](https://www.redhat.com/en/topics/containers/containers-vs-vms) 에서 표현한 가상머신과 컨테이너의 차이를 잘 설명해주고 있음
요약
컨테이너 - 애플리케이션에 필요한 소스 코드나 실행에 필요한 파일들만 포함하고 있어 가벼움
가상머신 - 데이터베이스처럼 애플리케이션 실행에 필요한 모든 구성 요소를 전부 포함하고 있어 무거운 경향이 있음
엔지니어는 데이터베이스, 웹서버, 시스템 서비스 등을 하나의 가상 머신에 전부 설치하고 그 가상 머신 안에서 모든 것이 잘 동작하도록 시스템을 구성하는 경우가 많았기 때문이다.

이러한 유형의 일체형 애플리케이션은 모놀리식으로 결합되어 상호의존성이 높다는 특징이 있음
반면, 마이크로 서비스는 데이터베이스 같은 시스템 요구사항에서 완전히 분리되어 독립적으로 실행할 수 있는 애플리케이션

마이크로서비스를 위해 가상 머신을 사용할 수도 있지만, 마이크로서비스에는 컨테이너 기술을 사용하는 것이 그 도구의 취지에 더욱 적합하다고 볼 수 있음

4.2절에서는 사전학습된 머신러닝 모델을 담은 컨테이너를 '소스코드 형태'로 구축하는 방법을 실습하며 자동화 개념과 연관지어 고민해보는 시간을 가진다.

### 컨테이너 런타임
#### 도커
컨테이너를 생성, 관리, 실행하는 도구로 개발되었음
그래서 이 도구를 통해 생성되고 실행되는 컨테이너를 '도커 컨테이너'라고 불렀음
#### 런타임
시스템에서 컨테이너를 생성, 관리, 실행하는 일 중에서 특히 실행하는 데 필요한 소프트웨어를 컨테이너 런타임이라고 부름.
새로운 런타임과 함께 사용될 수 있는 새로운 컨테이너 도구들이 만들어지고 있으며, 이들은 도커에서 제공하는 도구들과 상당 부분 호환된다. 컨테이너 런타임은 유일하지 않고, 도커는 런타임 그 자체가 아니라는 사실을 인지하도록 하자

### 컨테이너 생성하기
도커 컨테이너를 만드는데 필요한 과정
Dockerfile은 컨테이너 생성의 핵심
도커파일은 컨테이너 이미지 생성과 관련된 여러 명령문들을 작성할 수 있음
새 파일을 열어 파일명을 Dockerfile로 지정하고

교재에서 준 코드에서 || true를 붙여줘야 작동함 (mac에서만 그런건지는 확인 안됨)
```bash
FROM centos:8
RUN dnf install -y python38 || true
```
두 개의 문장으로 구성된
인스트럭션 : FROM이나 RUN 같은 키워드를 말함
FROM : 첫째 줄에 컨테이너 기반의 이미지를 지정하는 명령어
콜론으로 지정된 태그 값(숫자 8)는 CentOS의 버전을 의미함
컨테이너의 태그에는 일반적으로 버전과 같은 시간적 순서를 의미하는 정보가 기록되어 있음
정의된 태그가 없는 경우 기본적으로 'latest'태그가 적용됨

컨테이너 하나가 여러 개의 작은 레이어로 구성되어 있는 것은 큰 장점임

각각의 레이어는 다른 컨테이너를 만드는 일에도 사용될 수 있음
레이어 기반의 워크플로 덕분에 베이스 레이어 이미지를 컨테이너를 만들 때마다 다운로드 받지 않을 수 있는 것
실제로 베이스 이미지를 한 번 저장해두고 계속 재활용 하게 됨
레이어라는 개념이 존재하지 않아서 조금이라도 구성요소가 다르면 반드시 전체를 다시 다운로드 받아야 하는 가상 머신 기술에 비해 두드러지는 장점임

둘째줄의 RUN 명령은 시스템 명령을 실행.
CentOS 버전 8에는 기본적으로 실행되어 있지 않은 python을 설치하는 것
패키지 관리자 dnf을 실행할 때 -y 플래그를 함께하여 사람이 키보드 입력을 통해 확인을 할 필요가 없이 진행되도록 만든다는 점
설치 중 사용자 입력 대기 상태가 이미지 빌드를 정지시킬 수 있으므로 명령어 실행 시 사용자 입력 대기 상태를 자동으로 넘어가도록 설정하는 것이 중요함

도커파일이 존재하는 디렉토리에서 컨테이너 이미지를 빌드
```bash
docker build .
```
빌드를 통해 생성된 이미지에 대한 정보 확인하기
```bash
docker images
```

태그를 붙이는 방법
```bash
docker build -t localbuild:removeme .
```
TAG가 removeme라는 내용으로 docker images에서 확인이 가능함

```bash
docker images localbuild
```
REPOSITORY가 localbuild인 images 출력

변경사항이 없는 빌드 과정은 매우 빠르게 진행되었음
빌드 시스템이 이미 빌드된 이미지에 저장소와 태그 정보를 지정할 뿐이지
빌드 자체를 처음부터 다시 진행하는 것이 아니기 때문임

localbuild:removeme 이미지를 컨테이너 이미지 레지스트리의 localbuild 저장소에 푸시할 수 있다.
```bash
docker push localbuild:removeme
```
이 코드는 denied되는데 localbuild 저장소 소유주가 아니므로 푸시가 거부됨

```bash
docker tag localbuild:removeme yoong98/removeme
docker push yoong98/removeme
```
이는 (계정이름 / 저장소이름) 으로 구성되도록 만들면 컨테이너 이미지를 push할 수 있다.
반대로 pull 하고 싶은 경우는
```bash
docker pull yoong98/removeme
```
로 수정한다면 pull이 가능함

### 컨테이너 실행하는 방법
가상 머신을 사용할 때는 시큐어 셀(SSH) 데몬을 사용하도록 설정하여 특정 포트를 열어 접속이 가능하도록 외부에 노출시켜 SSH연결을 시도할 때마다 사용자의 암호 입력을 대기하지 않도록 기본 SSH 키를 추가하는 경우가 많아졌음

가상 머신과 마찬가지로 컨테이너 인스턴스에 접속할 때에도 SSH를 이용이 가능함
하지만 컨테이너 접속하기 위해 꼭 SSH를 이용할 필요는 없음
실행 중인 컨테이너에 접속할 때 권장되는 방법은 따로 있음
```bash
docker run -it -d --name centos-test --rm centos:8 /bin/bash [container ID]
```

#### -it 플래그
TTY(터미널 에뮬레이터)가 컨테이너에 할당되고, 할당된 TTY에 stdin이 연결됨
우리가 사용하는 터미널과 TTY가 상호작용할 수 있는 상태가 된다.
#### -d 플래그
컨테이너를 백그라운드에서 작동
#### --name 플래그
컨테이너에 centos-test라는 이름을 붙여줌
#### --rm 플래그
컨테이너가 종료되는 경우 해당 컨테이너가 완전히 제거 되도록 설정

```bash
docker ps
```
도커파일에 ENTERYPOINT 명령을 사용하여 /bin/bash를 명시적으로 입력하지 않아도 되도록 만들어보기
```Dockerfile
FROM centos:8
RUN dnf install -y python38 || true
ENTRYPOINT ["/bin/bash"]
```

```bash
docker build -t localbuild:removeme .
docker run --rm -it -d localbuild:removeme
```

```bash
docker ps
```
SSH와 실행중인 컨테이너에 접속하기 위해 일반적으로 사용되는 방법이 조금 다름
컨테이너에서도 SSH를 이용한 접속이 가능하지만 권장하진 않음
대신 컨테이너 ID와 docker exec 명령어를 사용하면 실행 중인 컨테이너에 접속이 가능함
```bash
docker exec -it bed19dd55627 bash
```
위 코드를 통해 docker의 bash에 접근이 가능해짐
셸을 통해 실행 명령을 입력할 수 있는 컨테이너를 사용하고 싶었기 때문에 exec 명령어를 토앻 배시 실행 명령을 전달했음.

컨테이너의 배시 셸에 터미널을 연결하면 명령어를 컨테이너에 편리하게 전달할 수 있기 때문
exec 명령어를 통해 배시 실행 명령을 전달
컨테이너의 배시 셸에 터미널을 연결하면 명령어를 컨테이너에 편리하게 전달할 수 있기 때문

컨테이너 셸을 제어할 필요가 없고 컨테이너를 통해 단지 명령어 한두개 정도만 실행하면 되는 경우도 있음.
exec 명령어로 실행 중인 컨테이너에 아래와 같이 일회성 명령을 전달
명령을 한 번만 전달할 때는 -it 플래그를 생략할 수 있음
```bash
docker exec bed19dd55627 tail /var/log/dnf.log
```

### 컨테이너 모범 사례
#### linter(린터) 사용

새로운 언어나 도구를 배우기 시작할 때 사용 규칙이나 패턴을 익히는 일은 누구에게나 어려움
추천하는 방법은 그 언어나 도구의 린터를 찾아보는 것
도커파일을 작성하여 컨테이너를 만드는 것을 배워나갈 때 대표적인 린터

hadolint
이 린터는 사용하기 편하도록 컨테이너 이미지로 패키징 되어 있다.
사용했던 도커파일 예제를 다음과 같이 수정
```Dockerfile
FROM centos:8
RUN dnf install -y python38 || true
RUN pip install pytest || true
ENTRYPOINT ["/bin/bash"]
```

hadolint로 검사해서 제안 받아보기
```bash
docker run --rm -i hadolint/hadolint < Dockerfile
```

#### 명령어 통합
컨테이너 기반 개발에서는 최대한 컨테이너를 작게 유지하려고 노력하는 경향이 있음
모든 컨테이너 도구도 마찬가지로 컨테이너 크기를 최대한 작게 유지하기 위해 노력함
컨테이너 도구를 사용하는 입장에서는 도커파일을 작서앟ㄹ 때 몇 가지만 유념해도 모두의 목표를 달성하는데 도움을 줄 수 있음
도커파일에서 RUN 명령이 등장할 때마다 하나의 새로운 레이어가 생성됨
컨테이너 이미지를 만드는데 사용되는 레이어가 적어야 컨테이너의 크기가 작아질 것임
```bash
RUN apk add --no-cache python3 && python3 -m ensurepip && pip3 install pytest || true
```
명령어 끝에 &&을 사용하여 여러 명령어를 하나로 묶어 단일 레이어로 만들 수 있음
한개에서 두개정도를 묶었을 때는 체감이 어렵지만 많은 양의 RUN 명령어로 분할된다면 컨테이너가 엄청 커질 것임 의존 패키지가 늘어날 수록 더 체감될 것

#### 취약성 분석
설치할 소프트웨어와 연관된 취약성이 있지는 않은지 확인하는 일도 중요함
대부분의 개발자는 고품질의 코드를 작성하려 노력하기 때문에 자신의 프로그램에 보안 취약점이 발견되지 않을 것이라고 생각한다. 하지만 컨테이너는 내가 직접 작성한 프로그램뿐 아니라 컨테이너가 빌드될 때 설치되었던 라이브러리들을 함께 구성한다는 사실을 잊지 않아야함

컨테이너는 빌드 될 때 애플리케이션 구동에 필요한 의존성들을 풀하는 일종의 운영체제와 비슷함
플라스크를 다운받았다 하면 플라스크의 수많은 종속성을 다운로드받게 된다. 이중 하나 때문에 보안 취약점(CVE)이 생길 수도 있다는 사실을 알아야 함
CVE는 언제든지 보고될 수 있기 때문에 취약성 경고에 사용되는 소프트웨어 시스템은 보고시 늦지 않게 알릴 수 있도록 하루에도 여러 번 업데이트되어야 한다.
최신 버전의 프레임워크가 지금 당장 취약하지 않을 가능성이 높지만 다음날 아침에 CVE가 보고될 가능성이 정확히 0%가 아니라는 사실을 기억해야 한다. 많은 보안 솔루션이 이러한 취약점들로 인해 발생하는 위험을 줄이기 위해 컨테이너의 취약성을 검사하고 보고하는 작업에 트고되어 있음

Anchore 사가 공개한 grype는 쉽게 설치하여 빠르게 사용해볼 수 있는 컨테이너 이미지 보안 도구임
grype 설치하기
현재 작업 디렉토리의 bin/경로에 배치되도록 설치하기
```bash
curl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sh -s
```


brew로 설치하기
```bash
brew tap anchore/grype
brew install grype
```
grype 실행파일을 지속적 통합 시스템에 배치하면 취약성을 자동으로 보고하도록 만들 수 있을 것임

grype 사용해보기
```bash
grype python:3.8
```
라고 하면 몇 백개가 나옵니다.
![[Pasted image 20231012155057.png]]
심각성이 높은 결과만 출력하기
```bash
grype python:3.8 | grep High
```
![[Pasted image 20231012155214.png]]
심각성이 높은 것만 추려서 표현해준 것이고
우리는 이중에서 우리가 사용하는 것이 있으면 우리가 만든 시스템이 멈춰버릴 가능성이 있다는 것으로 판단하면 될 것임

이 컨테이너를 사용하고 하더라도 해당 기능을 사용하지 않는다면 시스템이 위험하지는 않음
중요한 것인 서비스를 프로덕션 환경으로 배포하기 전에 취약점을 보고받을 수 있고, 이를 컴토하여 적절한 판단을 내리는 것

심각성이 높은 취약점이 발견되면 검사를 실패로 간주하도록 만드는 방법
```bash
grype --fail-on=high centos:8
```
### HTTP로 모델 서빙하기
플라스크ㅡ 웹 프레임워크 기반의 간단한 HTTP API를 통해 훈련된 모델을 서빙하는 컨테이너
requirements.txt 파일이 작업 디렉토리에 있다고 가정하고 작성해보기
```Dockerfile
FROM python:3.8
ARG VERSION
LABEL org.label-schema.version=${VERSION}
RUN python3 -m pip install --upgrade pip
COPY ./requirements.txt /ws/requirements.txt
WORKDIR /ws
RUN pip install -r requirements.txt
COPY ./webapp/ /ws
ENTRYPOINT [ "python3" ]
CMD [ "app.py" ]
```
#### ARG 명령어
VERSION이라는 인수를 정의
이 인수는 LABEL 명령어에서 변수로 쓰임
LABEL 명령어를 이용하면 컨테이너에 레이블을 지정할 수 있음 
이때 레이블 [스키마 컨벤션](https://oreil.ly/PtOSK)을 이용하면 레이블 형식을 정규화 할 수 있다.

컨테이너 이미지에 포함된 날로부터 오랜 시가닝 지나서 컨테이너에서 실행되고 있는 모델을 교체하거나 재학습하는 상황
도커 컨테이너에 직접 접속 - 모델 확인해보는 등의 복잡한 작업 없이도 빠르게 컨테이너에서 실행되고 있는 모델에 대한 정보를 담고 있는 레이블은 큰 도움이 될 수 있음

- 저장되어있는 파일

---
.
|- Dockerfile
|- notebooks
|- webapp
|- predict.py
|- requirements.txt

컨테이너에 이미지 빌드하기
```bash
docker build . -t flask-docker:v1 --build-arg VERSION=AutoMPGDNNv1
```
빌드 확인하기
```shell
docker images flask-docker
```
-p 옵션을 이용해 컨테이너의 5000번 포트를 노출시키면서
호스트 컴퓨터의 5001번 포트에 컨테이너를 5000번 포트를 매핑
--name 옵션을 이용해 컨테이너 이름을 자동으로 생성하는 대신 flask-docer로 명시
-d 플래그를 사용해 컨테이너가 백그라운드에서 실행되도록 하기
```bash
docker run --rm -p 5001:5000 -d --name flask-docker flask-docker:v1
```
(일단 컨테이너에서 에러가나는데 표시는 안되는것 같음 추후에 필요시 확인하기)
```bash
curl localhost:5001
```

## 엣지 디바이스
'엣지 디바이스'란 쉽게 말해 사용자와 물리적으로 가깝지만 연산자원이 제한적인 스마트폰, 라즈베리 파이, 마이크로컨트롤러와 같은 기기를 의미함
엣지 디바이스 머신러닝 시스템 구축의 목표는 사용자의 요청을 데이터센터까지 전송하고 값비싼 연산을 거친 뒤 결과값을 반환하는 대신 사용자의 요청에 훨씬 빠른 응답을 제공하는 것

엣지 컴퓨팅은 연산 자원이 사용자에게 가까울수록 사용자의 요청에 대한 응답이 빨라질 것이라는 당연한 아이디어서 출발함
엣지 디바이스와 데이터 센터 중 어느 위치에 머신러닝 모델을 배포할지는 어느정도 정해져 있다고도 할 수 있음
프로세서는 점점 더 작아지고 빨라지며 머신러닝에 특화된 프로세서들도 빠른속도로 개발되고 있음

사용자 가까이에 위치한 엣지 디바이스에서 빠른 추론을 수행할 수 있는 방법들과 이를 통해 얻을 수 있는 이점에 대해 살펴 볼 것

### 구글 코랄
엣지 배포의 본질은 빠르고, 사용자와 밀접하게 상호작용하고, 인터넷 없이도 잘 작동하도록 만드는 것
코랄 프로젝트는 엣지 배포의 본질을 지키며 엣지 디바이스에서 머신러닝 추론을 할 수 있도록 돕는 플랫폼
텐서플로 라이트 모델을 실행할 수 있는 USB 형태의 가속기에 대해 두루기.

엣지 디바이스에서 머신러닝 모델이 실행되도록 만들 때 고려해야하는 점들
1. 실행하고자 하는 머신러닝 연산 및 가속이 지원되는 하드웨어인지 확인해야 함
2. 엣지 디바이스에 머신러닝 모델을 설치하는 방법이 잘 안내되어 있는지
3. 엣지 배포 관련 소프트웨어 간의 호환성은 괜찮은지를 확인해야한다.
코랄 엣지 TPU는 이 세가지 측면을 모두 충족했다고 생각함
대부분의 텐서플로 라이트 모델들은 컴파일만 무사히 마치면 별다른 문제없이 TPU에서 실행이 가능하다.

간단한 코랄 예제를 실행하기 위해서는 코랄 TPU 런타임과 텐서플로 런타임이 필요함
코랄 TPU 런타임 스크립트로 설치하기
```bash
curl -LO https://github.com/google-coral/libedgetpu/releases/download/release-grouper/edgetpu_runtime_20221024.zip
```

압축해제
```bash
unzip edgetpu_runtime_20221024.zip
```
설치
```bash
cd edgetpu_runtime
sudo bash install.sh
```

TPU가 정상적으로 작동하는지 확인하는 작은 머신러닝 모델을 
TPU에서 실행하는 파이썬 스크립트 제공하는 것을 복제
```bash
mkdir google-coral && cd google-coral
git clone https://github.com/google-coral/tflite --depth 1
cd tflite/python/examples/classification
```

가상환경을 활성화 한 후 which 명령어가 찾는 파이썬 인터프리터 실행 파일의 경로가 시스템 기본 경로가 아닌 가상환경의 파이썬 인터프리터인지 확인하기
```bash
which python3
python3 -m venv coral-venv
```

source에 대한 책에서 오탈자가 있는듯
coral-venv를 실행해야할 것 같음
```bash
source coral-venv/bin/activate
which python
```

### 애저 퍼셉트
코랄 엣지 TPU와 같은 엣지 디바이스에 머신러닝 모델을 배포하는 
본질적인 이유가 애저 페셉트에도 동일하게 적용됨
애저 퍼셉트도 머신러닝 작업들이
애저에서 원활하게 동작할 수 있도록 돕는다.

### 텐서플로 허브
텐서플로 모델을 찾을 수 있는 훌륭한 리소스는 텐서플로 허브임
사전학습된 텐서플로 모델 수천개가 보관되어 있음
다운로드 받은 모델을 코랄 엣지 TPU에 사용한다면 정상적으로 작동하지 않는 문제를 맞닥뜨릴 가능성이 있음
TPU의 특수한 명령들을 사용하기 위해 TPU가 실행 가능한 형태로 컴파일 되지 않았기 때문

TPU에서 곧바로 실행 가능한 형식의 사전학습 모델만을 골라볼 수 있는 기능을 제공
코랄 형식을 클릭하여 엣지 TPU에 사용할 수 있는 목록을 볼 수 있음
[텐서플로 허브](https://tfhub.dev)
[텐서플로 코랄 형식](https://oreil.ly/mJv9N)

MobileNet Quantized V2 분류모델은 물체를 분류해 낼 수 있도록 사전학습되어 있음
머신러닝 모델의 출력값을 이해하기 위해 레이블 정보를 다운로드 받아야한다.
(하나의 모델이 다양한 형식으로 게시되어 있을 수 있음 코랄에서 모델을 실행할 목적이라면 텐서플로 허브에서 모델을 다운로드 받기 전에 코랄에서 사용가능한 포맷인지 꼭 확인하여야 한다.)

### 구글 코랄 엣지 TPU 컴파일러
사용 목적에 부합하는 모델을 찾았음에도 TPU 장치에서 작동할 수 있는 형태로 컴파일되어 있지 않아 코랄에서 사용하지 못할 수 있다. 이러한 상황들에 대응할 수 있도록 코랄팀은 엣지 TPU 컴파일러를 제공함

공식 문서에 따르면 컴파일러는 데비안 또는 우분투 리눅스에만 설치가 가능하지만 컨테이너 기술을 사용한다면 운영체제 호환성 문제를 회피할 수 있다. 컴파일러 문제를 해결하기 위한 데비안 기반 컨테이너를 만들고 필요한 프로그램을 설치해보기
(ARM 아키텍처에서는 불가능)

```Dockerfile
FROM debian:stable

RUN apt-get update && apt install -yq curl build-essential gnupg
RUN curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
RUN echo "deb https://packages.cloud.google.com/apt coral-edgetpu-stable/main" | tee/etc/apt/sources.lost.d/coral-edgetpu.list
RUN apt-get update && apt-get install -yq edgetpu-compiler

CMD ["/bin/bash"]
```

책 내용과 유사한 구글 [코랩 튜토리얼](https://colab.research.google.com/github/google-coral/tutorials/blob/master/compile_for_edgetpu.ipynb)

## 완전 관리형 머신러닝 시스템을 위한 컨테이너
MLOps 워크플로의 핵심은 AWS 세이지메이커, 애저 머신러닝 스튜디오, 구글의 버텍스 AI같은 높은 추상화 수준의 머신러닝 시스템
이 모든 시스템은 컨테이너 위에서 구축된다고 해도 과언이 아님

![[30C2B766-4B90-4ABE-85BD-CBFC5D799CDF_1_102_a.jpeg]]
EC2 컨테이너 레지스트리는 추론 이미지와 학습 이미지가 존재하는 위치이다.
컨테이너 레지스트리에 소스 코드 이미지를 만들어 두는 것은 지속적 통합과 지속적 배포 측면에서 DevOps모범 사례에 해당함
컨테이너 기술은 소프트웨어를 '하나의 완성품'처럼 관리하며 복잡성을 줄이고 머신러닝 아키텍처의 품질을 향상 시킬 수 있다.
복잡성을 관리하는 일을 자동화하여 리소스를 절약하면 데이터 드리프트를 보정하는 일, 새로운 모델을 만들기 위해 피처 스토어에서 모델 학습에 적합한 특징을 탐색하는 일, 새로운 모델이 고객의 요구사항을 만족하고 있는지를 평가하는 일과 같은 중요한 문제들에 절약한 리소스를 분배할 수 있다.

### MLOps 컨테이너 거래하기
AWS 마켓플레이스에서 판매되는 알고리즘이나 모델을 구매하거나 판매가 가능함

### 다양하게 활용되는 컨테이너
컨테이너 기반의 MLOps는 제품화와 개발 모두에 용이하도록 다양한 옵션을 제공한다.
컨테이너가 중심이 되는 MLOps에서 컨테이너로 패키징되어 레지스트리에 등록된 이미지는 여러 환경으로 배포되고 사용될 수 있다.
MLOps와 컨테이너 기술은 컨테이너가 비즈니스 가치를 제공하는데 도움이 된다는 점에서 상호 보완적이다.

### 마치며
컨테이너를 이용한 머신러닝 모델 배포 그리고 엣지 환경과 관련하여 반드시 알아야 할 내용을 정리함
머신러닝 모델을 운영하며 배포를 해야하는 상황에 놓이면 여러 고민을 하게 된다.
컨테이너 기술은 환경을 더 빠르고 안정적으로 재현할 수 있도록 지원한다.
시스템 환경은 반복적으로 재현 가능하도록 만드는 것은 불과 몇 년 전만 해도 어려운 문제였음
이러한 문제를 해결하는 데 컨테이너 기술이 크게 기여했음
컨테이너와 클라우드를 이용하여 자원을 필요에 따라 빠르게 확장하거나 축소하여 예시들에서 살펴볼 수 있듯이 배포 환경을 쉽게 전환이 가능하였음
최근에는 스마트폰이나 그보다 훨씬 작은 마이크로디바이스에 모델을 배포하는 일이 흔해지고 있음
엣지 디바이스에서 수행되는 추론 작업은 오프라인 환경에서도 동작할 수 있다는 장점이 있고 서버에 모델이 위치하는 것보다 훨씬 빠르고 안정적이라는 특징이 있음.