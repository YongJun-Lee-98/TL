# 빅데이터 분석 기획
## <mark style="color: #FF0000FF">빅데이터의 이해</mark>
### <mark style="color: #FFA500">빅데이터의 개요 및 활용</mark>
### <mark style="color: #FFA500">빅데이터 기술 및 제도</mark>
## <mark style="color: #FF0000FF">데이터 분석 계획</mark>
### 분석 방안 수립
### 분석 작업 계획
<h2 style="color: #FF0000FF">데이터 수집 및 저장 계획</h2>
<h3 style="color: #FFA500">데이터 수집 및 전환</h3>
<h4 style="color: #FFFF00">데이터 수집</h4>
<h5 style="color: #008000">데이터 수집 수행자료</h4>
용어집, 원천 데이터 소유 기관 정보, 서비스 흐름도, 데이터 수집 기술 매뉴얼, 업무 매뉴얼, 인프라 구성도, 데이터 명세서, 소프트웨어 아키텍처 개념도, 데이터 수집 계획서, 수집 솔루션 매뉴얼, 원천 데이터 담당자 정보, 하둡 오퍼레이션 매뉴얼, 비즈니스 및 원천 데이터 파악을 위한 비즈니스 모델
<h5 style="color: #008000">비즈니스 도메인과 원천 데이터 정보 수집</h5>
1. 비즈니스 도메인 정보 - 비즈니스 모델, 비즈니스 용어집, 비즈니스 프로세스, 도메인 전문가 인터뷰
2. 원천 데이터 정보 - 데이터의 수집 가능성, 데이터의 보안, 데이터의 정확성, 수집 난이도, 수집 비용
<h5 style="color: #008000">내﹒외부 데이터 수집</h5>
1. 데이터의 종류 - 
   내부데이터(서비스 시스템, 네트워크 및 서버 장비, 마케팅 데이터),
   외부데이터(소셜 데이터, 특정 기관 데이터, M2M 데이터, LOD)
2. 데이터의 수집 주기 - 내부(실시간 분석), 외부(수집 데이터 관리 정책)
3. 데이터의 수집 방법 - 내부(가공 적은 노력), 외부(목표에 맞는 탐색, 수집, 분석 필요)
<h5 style="color: #008000">데이터 수집 기술</h5>
1. 데이터 유형별 데이터 수집 기술
   정형 - ETL, FTP, API, DBToDB, 스쿱(Sqoop)
   비정형 - 크롤링, RSS, Open API, 척와(Chukwa), 카프카(Kafka)
   반정형 - 플럼(Flume), 스크라이브(Scribe), 센싱(Sencing), 스트리밍(Streaming)
2. ETL(Extract Transform Load)
   Extract - 추출, Transform - 변환, Load - 적재
3. FTP 파일전송 시스템임 TCP/IP 위에서 동작
   서버와 접속하는 두 클라이언트 사이에 두 개의 연결을 생성하여 파일 송수신 작업은 데이터 전송 연결에서 처리
4. 정형데이터 수집인 스쿱(Sqoop) 기술
   데이터 스토어 간 대량 데이터를 효과적으로 전송하기 위해 구현된 도구
   특징 - Bulk import 지원(분산 파일시스템 지원), 데이터 전송 병렬화, Direct input 제공, 프로그래밍 방식의 데이터 인터랙션
5. 로그/센서 데이터 수집 플럼(Flume) 기술
   플럼 특징 - 신뢰성, 확장성, 효율성
6. 스크래피(Scrapy) 기술
   웹사이트 크롤링하는 도구
   특징 - 파이썬 기반, 단순한 스크랩 과정, 다양한 부가 요소
<h4 style="color: #FFFF00">데이터 유형 및 속성 파악</h4>
<h5 style="color: #008000">데이터 수집 세부 계획 작성</h5>
데이터 선정 이후 - 유형, 위치, 저장방식, 수집기술, 보안사항 등
<h5 style="color: #008000">데이터 유형과 위치 및 비용</h5>
1. 데이터 유형
   정형 - RDB, File
   반정형 - HTML, XML, JSON, RSS, 웹로그, 센서 데이터
   비정형 - 동영상, 이미지, 텍스트
2. 데이터 위치
3. 데이터 확보 비용 산정
   요소 - 데이터의 종류, 크기 및 보관 주기, 수집 주기, 수집 방식, 수집 기술, 가치성
<h5 style="color: #008000">수집되는 데이터 형태</h5>
1. HTML
   텍스트, 태그, 스크립트로 구성됨
2. XML
   데이터 표현을 위해 tag형태로 사용됨
   엘리먼트(쌍으로 존재하는 태그), 속성, 처리명령, 엔티티(<>, &를 사용해 특정 문자열로 대체하는 것), 주석, CDATA 섹션
3. JSON
   수, 문자열, 배열, 객체
<h5 style="color: #008000">데이터 저장 방식</h5>
1. 파일 시스템
2. 관계형 데이터베이스
3. 분산처리 데이터베이스
<h5 style="color: #008000">데이터 적절성 검증</h5>
1. 데이터 누락 점검 : 수집 데이터 세트의 누락, 결측 여부 판단하여 재수집
2. 소스 데이터와 비교 : 수집 데이터와 소스 데이터의 사이즈 및 개수를 비교 검증
3. 데이터의 정확성 점검 : 유효하지 않는 데이터 존재여부 점검
4. 보안 사항 점검 : 수집 데이터의 개인정보 유무 등
5. 저작권 점검 : 데이터의 저작권 등 법률적 검토를 수행
6. 대량 트래픽 발생 여부
<h4 style="color: #FFFF00">데이터 변환</h4>
<h5 style="color: #008000">데이터 변환</h5>
1. 데이터 변환 방식의 종류
   비정형 -> 정형 (관계형 데이터베이스)
   수집 -> 분산파일 (HDFS)
   주제별, 시계열적으로 저장 (데이터웨어하우스)
   키-값 형태로 저장 (NoSQL)
2. 데이터 변환 수행 자료
   데이터 수집 계획서, 수집 솔루션 매뉴얼, 데이터 변환 솔루션, 하둡 오퍼레이션 매뉴얼, 소프트웨어 아키텍처 개념도
<h5 style="color: #008000">데이터베이스 구조 설계</h5>
1. DBMS 구축 여부 결정 - 필요 데이터 속성 파악후 구축 여부 결정
   저장 데이터베이스는 분석이 쉬운 RDBMS를 보편적으로 사용한다
2. 저장 데이터베이스 결정
3. DBMS 설치
4. 테이블 구조 설계
<h5 style="color: #008000">비정형/반정형 데이터의 변환</h5>
1. 수집 데이터의 속성 구조 파악 (적절한 변수명으로 구분)
2. 데이터 수집 절차에 대한 수행 코드 정의 (정보들의 위치와 구조 파악, 필요데이터 추출)
3. 데이터 저장 프로그램 작성
4. 데이터베이스에 저장
<h5 style="color: #008000">융합 데이터베이스 설계</h5>
1. 요구사항 분석
2. 데이터 표준화와 모델링 수행
   표준화 - 표준 코드, 표준 용어, 데이터 도메인 등을 정의
   엔티티(정보 최소단위)와 에트리뷰트를 추출하여 
   개념적 설계와 관계형 스키마 작성하는 논리적 설계 수행
   IT 기술 - IT기술번호, 이름, 분야, 보급률
   정책기관 - 정책기관번호, 이름, 전화번호, 주소
   조사 - 정책기관번호, IT기술번호, 조사명, 조사일자, 조사내용
   
   논리적 설계 - 작성된 ER 다이어그램을 기반으로 매핑하여 관계형 스키마 생성
<h5 style="color: #008000">고려사항</h5>
비정형, 반정형 -> 정형화된 데이터베이스로 변환에 집중
속성 구조를 정확히 파악해야 쉽게 저장이 가능
쉽게 자동화 구축될 수 있도록 설계하여야 함
<h4 style="color: #FFFF00">데이터 비식별화</h4>
<h5 style="color: #008000">데이터 비식별화 개요</h5>
개인을 알아볼 수 없도록 하는 조치
1. 식별자와 속성자
   개인 또는 개인과 관련한 사물에 고유하게 부여된 값
   식별자 해당사항
   고유식별번호 / 성명 / 주소 / 날짜정보 / 전화번호 / 의료기록번호 / 통장 / 자격정보 / 사진 / 자동차 번호 등
   개인정보는 살아있는 개인에 관한 정보로 개인을 알아볼 수 있는 정보
2. 비식별 조치 방법
   가명처리 - 휴리스틱 가명화 / 암호화 / 교환 방법
   총계처리 - 총계처리 / 부분총계 / 라운딩 / 재배열
   데이터삭제 - 식별자 삭제 / 식별자 부분삭제 / 레코드 삭제 / 식별요소 전부 삭제
   데이터 범주화 - 감추기 / 랜덤 라운딩 / 범위 방법 / 제어 라운딩
   데이터 마스킹 - 임의 잡음 추가 / 공백과 대체
<h5 style="color: #008000">가명처리</h5>
장점 - 데이터 변질 및 수준이 적다
단점 - 대체 값 부여 시에도 식별가능한 고유 속성이 유지됨
1. 휴리스틱 가명화
   식별자에 해당하는 값들을 정해진 규칙으로 대체하거나 가공
2. 암호화
   정보 가공시 일정한 규칙의 알고리즘으로 암호화
   일방향 암호화는 식별성을 완전히 제거하는 것으로, 양방향 암호화에 비해 더욱 안전하고 효과적인 비식별 기술에 해당
3. 교환 방법
   사전에 정해진 외부의 변수 값과 연계하여 교환한다.
<h5 style="color: #008000">총계처리</h5>
장점 - 민감한 수치 정보에 대하여 비식별 조치가 가능하며, 통계분석용 데이터셋 작성에 유리하다.
단점 - 정밀한 분석이 어려우며, 집계 수량이 적을 경우 추론에 의한 식별 가능성이 있다.
1. 부분총계
   데이터셋 내 일정부분 레코드만 총계 처리하며, 다른 데이터 값에 비하여 오차범위가 큰 항목을 통계값으로 변환한다.
2. 라운딩
   집계 처리된 값에 대하여 라운딩(올림, 내림, 반올림) 기준을 적용하여 최종 집계 처리하는 방법이다. - 세세한 정보보다는 전체 통계정보가 필요한 경우 많이 사용
3. 재배열
   기존 정보 값은 유지하며 개인이 식별되지 않도록 데이터를 재배열
<h5 style="color: #008000">데이터 삭제</h5>
장점 - 개인 식별요소의 전부 및 일부 삭제 처리가 가능하다.
단점 - 분석의 다양성과 분석 결과의 유효성﹒신뢰성이 저하됨
1. 식별자 (부분)삭제
2. 레코드 삭제
3. 식별요소 전부삭제
<h5 style="color: #008000">데이터 범주화</h5>
장점 - 통계형 데이터 형식이므로 다양한 분석 및 가공 가능하다.
단점 - 정확한 분석결과 도출이 어려우며, 데이터 범위 구간이 좁혀질 경우 추론 가능성이 있다.
1. 감추기
   명확한 값을 숨기기 위하여 데이터의 평균 또는 범주 값으로 변환하는 방식
2. 랜덤 라운딩
   수치 데이터를 임의의 수 기준으로 올림 또는 내림하는 기법수치 데이터 이외의 경우에도 확장 적용이 가능
3. 범위 방법
   수치 데이터를 임의의 수 기준의 범위로 설정하는 기법
4. 제어 라운딩
   행과 열이 맞지 않는 것을 제어하여 일치시키는 기법
<h5 style="color: #008000">데이터 마스킹</h5>
장점 - 개인 식별요소를 제거하는 것이 가능, 원 데이터 구조에 대한 변형이 적음
단점 - 마스킹을 과도하게 적용할 경우 데이터 필요 목적에 활용하기 어려우며 마스킹 수준이 낮을 경우 특정한 값에 대한 추론이 가능하다.
1. 임의 잡음 추가
   개인 식별이 가능한 정보에 임의의 숫자 등 잡음(+ or x)을 추가하는 방법
   잡음 값은 데이터와는 무관하기 때문에, 유효한 데이터로 활용하기 곤란하다.
2. 공백과 대체
   특정 항목의 일부 또는 전부를 공백 또는 대체문자로 바꾸는 기법
<h5 style="color: #008000">적정성 평가</h5>
- 비식별 조치가 충분하지 않은 경우 공개 정보 등 다른 정보와의 결합, 추론 기법등을 통해 개인이 식별될 위험이 있으므로 개인정보 보호 책임자 책임 하에 개인식별 가능성에 대한 엄격한 평가가 필요함
- 적정성 평가 시 프라이버시 보호 모델 중 최소한의 수단으로 k-익명성을 활용하며, 필요시 추가적인 평가모델을 활용한다.
1. k-익명성 - <mark style="background:blue;color:white">주어진 데이터 집합에서 같은 값이 적어도 k개 이상 존재</mark>
   공개된 데이터에 대한 연결공격 등 취약점을 방어하기 위해 제안된 개인정보 보호모델로 비식별화 조치의 최소 기준으로 사용됨
2. l-다양성
   동질성 공격 및 배경지식에 의한 공격을 방어하기 위한 모델
   적어도 l개의 다른 정보를 가지도록 함
   충분히 다양한 서로 다른 정보를 갖도록 집합을 구성
3. t-근접성
   l-다양성의 취약점을 보완하기 위한 모델로 값의 의미를 고려하는 모델
   t-근접성은 동질 집합에서 특정 정보의 분포와 전체 데이터 집합에서 정보의 분포가 t이하의 차이를 보여야함
   t-근접성은 정보의 분포를 조정하여 정보가 특정 값으로 쏠리거나 유사한 값들이 뭉치는 경우를 방지하는 방법
<h4 style="color: #FFFF00">데이터 품질 검증</h4>
<h5 style="color: #008000">데이터 품질 관리</h5>
1. 품질 관리의 정의
   비즈니스 목표에 부합한 데이터 분석을 위해
   가치성, 정확성, 유용성 있는 데이터를 확보
2. 데이터 품질 관리의 중요성
   분석 결과의 신뢰성은 분석 데이터의 신뢰성과 직접 연계된다.
   데이터 품질 관리 체계를 구축하여 효과적인 분석결과를 도출하여야 한다.
   신뢰성 확보 / 일원화된 프로세스 / 데이터 활용도 향상 / 양질의 데이터 확보
<h5 style="color: #008000">데이터 품질</h5>
1. 정형 데이터 품질 기준
   완전성 / 유일성 / 일관성 / 유효성 / 정확성
2. 비정형 데이터 품질 기준
   기능성 / 신뢰성 / 사용성 / 효율성 / 이식성
<h5 style="color: #008000">데이터 품질 진단 기법</h5>
1. 정형 데이터 품질 진단
   메타데이터 수집 및 분석
   칼럼 속성 분석
   누락 값 분석
   값의 허용 범위분석
   허용 값 목록 분석
   문자열 패턴 분석
   날짜 유형 분석
   기타 특수 도메인
   유일 값 분석
   구조 분석
2. 비정형 데이터 품질 진단
   기능성 - 정확성 / 적절성 / 상호 운용성 / 기능 순응성
   신뢰성 - 성숙성 / 신뢰 순응성
   사용성 - 이해성 / 친밀성 / 사용 순응성
   효율성 - 시간 효율성 / 효율 순응성
   이식성 - 적응성 / 공존성 / 이식 순응성
<h5 style="color: #008000">데이터 품질 진단 절차</h5>
1. 품질 진단 계획 수립
2. 품질 기준 및 진단 대상 정의
3. 품질 측정
4. 품질 측정 결과 분석
5. 데이터 품질 개선
<h5 style="color: #008000">데이터 품질 검증 수행</h5>
수집 데이터 품질 보증 체계를 수립하여 품질 점검 수행 후 품질 검증 결과서 작성
품질 점검 수행 과정에서 데이터 오류수정이 용이하지 않은 경우 데이터를 재수집
<h2 style="color: #FFA500">데이터 적재 및 저장</h2>
<h3 style="color: #FFFF00">데이터 적재</h3>
<h4 style="color: #008000">데이터 적재 도구</h4>
- 수집한 데이터는 빅데이터 분석을 위해 저장 시스템에 적재
- 데이터 유형과 실시간 처리 여부에 따라
  관계형 데이터베이스 / HDFS 분산파일시스템 / NoSQL 저장시스템
  에 데이터를 적재할 수 있다.
- 저장시스템에 적재 시 Fluented / Flume / Scribe / Logstash 등의 데이터 수집 도구들을 이용하는 방법도 있다.
1. 데이터 수집 도구를 이용한 데이터 적재
   플루언티드(Fluentd) - 사용자의 로그를 다양한 형태로 받아서 JSON 포맷으로 변환 후 다양한 형태로 출력
   플럼(Flume) - 로그 데이터 수집과 네트워크 트래픽 데이터 등 대량의 이벤트 데이터 전송을 위해 사용
   스크라이브(Scribe) - 수많은 서버로부터 실시간으로 스트리밍되는 로그 데이터를 집약시키기 위한 서버
   로그스태시(Logstash) - 다양한 소스에서 데이터를 수집하여 변환 후 자주 사용하는 저장소
2. NoSQL DBMS가 제공하는 도구를 이용한 데이터 적재
   수집한 데이이터가 csv 등의 텍스트 데이터라면 mongoimport와 같은 적재 도구를 사용하여 데이터 적재를 수행할 수 있다.
<h4 style="color: #008000">데이터 적재 완료 테스트</h4>
1. 데이터 적재 내용에 따라 체크리스트를 작성
2. 데이터 테스트 케이스를 개발
3. 체크리스트 검증 및 데이터 테스트 케이스 실행

<h4 style="color: #008000">빅데이터 저장시스템</h4>
1. 파일 시스템 저장방식
   Apache HDFS(하둡 파일시스템) / GFS(구글파일시스템)
   저사양 서버들을 활용하여 대용량, 분산, 데이터 집중형의 애플리케이션을 지원
2. 데이터 저장방식
   관계형 데이터베이스 시스템을 이용하거나 NoSQL 데이터베이스 시스템을 이용하는 방식
   NoSQL은 수평적 확장성, 데이터 복제, 간편한 API제공, 일관성 보장등의 장점이 있음
<h4 style="color: #008000">분산 파일 시스템</h4>
1. 하둡 분산파일 시스템 (HDFS)
   대용량 파일을 클러스터에 여러 블록으로 분산하여 저장, 블록들은 마지막 블록을 제외하고 크기가 동일(64MB)
   마스터(Master) 한개 와 여러개의 슬레이브(Slave)로 클러스터링 되어 구성된다.
   마스터 노드 == 네임노드
   슬레이브 노드 == 데이터 노드 라고 하며 데이터 블록을 분산처리한다.
   데이터 손상을 방지하기 위해서 데이터 복제 기법을 사용한다.
2. 구글 파일 시스템 (GFS)
   구글 파일 시스템은 엄청나게 많은 데이터를 보유해야 하는 구글의 핵심 데이터 스토리지와 구글 검색 엔진을 위해 최적화된 분산 파일 시스템이다.
   마스터(Master), 청크 서버(Chunk Server), 클라이언트로 구성된다.
   마스터 - 전체 GFS 상태 관리 및 통제
   청크서버 - 물리적인 하드디스크의 실제 입출력을 처리
   클라이언트 - 파일 읽고 쓰는 동작을 요청하는 애플리케이션
   파일크기 (64MB)로 고정
   응답시간이 길더라도 데이터의 높은 처리성능에 중점을 두었음
3. NoSQL
   1. 개요
      유연한 데이터의 저장 및 검색을 위한 매커니즘을 제공
      대규모 데이터 처리를 위한 확장성, 가용성 및 높은 성능을 제공, 빅데이터 처리와 저장을 위한 플랫폼으로 활용
   2. CAP 이론 : 기존 데이터 저장 구조의 한계
      일관성 / 가용성 / 지속성
   3. NoSQL의 기술적 특성
      ACID(운자성, 일관성, 고립성, 지속성)특성 중 일부만을 지원하는 대신 성능과 확장성을 높이는 특성을 강조한다.
      특징
      - 무스키마
      - 탄력성
      - 질의 기능
      - 캐싱
   4. 데이터 모델
      키-값(Key-Value) 데이터베이스로 쌍으로 저장됨
      열기반(Column-oriented) 데이터베이스
      문서기반(Document-oriented) 데이터베이스
<h4 style="color: #008000">빅데이터 저장시스템 선정을 위한 분석</h4>
1. 기능성 비교분석
   - 데이터 모델
   - 확장성
   - 트랜잭션 일관성
   - 질의 지원
   - 접근성
2. 분석방식 및 환경
   필요로 하는 분석 및 검색결과가 상시로 온라인 형식으로 필요한지, 분석가를 통해 별도의 프로세스를 거쳐 제공받는지 등을 구분하여 저장 방식과 환경을 선택
3. 분석대상 데이터 유형
   데이터의 volume, velocity, variety, veracity 등을 고려하여 빅데이터 저장시스템을 선택한다.
4. 기존 시스템과의 연계
<h4 style="color: #008000">데이터 발생 유형 및 특성</h4>
1. 대용량 실시간 서비스 데이터 개요
   대용량의 특성과 무중단 서비스를 보장하는 저장체계를 구축해야함
   실시간 데이터 처리 - 스파크 / 스톰
2. 대용량 실시간 서비스 데이터 저장
   스파크/스톰을 사용한다면 저장소가 없으므로 외부 저장 시스템과 연동이 필수적임
<h4 style="color: #008000">안정성과 신뢰성 확보 및 접근성 제어계획 수립</h4>
1. 빅데이터 저장시스템 안정성 및 신뢰성 확보
2. 접근성 제어계획 수립
# 빅데이터 탐색
<h2 style="color: #FF0000FF">데이터 전처리</h2>
<h3 style="color: #FFA500">데이터 정제</h3>
<h4 style="color: #FFFF00">데이터에 내재된 변수의 이해</h4>
<h5 style="color: #008000">데이터 관련 정의</h5>
1. 데이터 : 이론을 세우는 기초가 되는 사실 또는 자료를 지칭
2. 단위 : 관찰되는 항목 또는 대상을 지칭
3. 관측값 : 각 조사 단위별 기록정보 또는 특성을 말함
4. 변수 : 각 단위에서 측정되는 특성 결과
5. 원자료 : 표본에서 조사된 최초의 자료를 이야기함
<h5 style="color: #008000">데이터의 종류</h5>
1. 단변량자료(Univariate Data) : 특성 변수가 하나인 자료
2. 다변량자료(Multivariate Data) : 특성 변수가 두 가지 이상인 자료
3. 질적자료(Qualitative Data) : 정성적 또는 범주형 자료라고 하며 자료를 범주의 형태로 분류 편의상 부여된 수치의 크기 자체에는 의미를 부여하지 않는 자료 명목자료, 서열자료 등이 질적자료로 분류
4. 수치자료(Quantitative Data) : 정량적 또는 연속형 자료. 숫자의 크기에 의미를 부여할 수 있는 자료를 나타냄. 구간자료, 비율자료가 여기에 속함
5. 시계열자료(Time Series Data) : 일정한 시간간격 동안에 수집된, 시간개념이 포함되어 있는 자료
6. 횡적자료(Cross Sectional Data) : 횡단면 자료라고도 하며 특정 **단일 시점**에서 여러 대상으로부터 수집된 자료. 한개의 시점 - 여러개의 자료
7. 종적자료(Longitudinal Data) : 시계열자료와 횡적자료의 결합으로 여러 개체를 여러 시점에서 수집한 자료이다.
<h5 style="color: #008000">데이터의 정제</h5>
1. 데이터 정제의 필요성
   수집된 데이터를 분석의 도구 또는 기법에 맞게 다듬는 과정이 필요
2. 정제과정을 거치지 않은 데이터의 문제점
   데이터 구성의 일관성이 없으지므로 분석의 처리에 어려움이 발생
   도출된 결과의 신뢰성 저하 발생
3. 데이터 정제의 과정(Processing)
   - 집계(Aggregation)
   - 일반화(Generalization)
   - 정규화(Normalization)
   - 평활화(Smoothing)
   - 데이터의 전처리﹒후처리
<h4 style="color: #FFFF00">데이터 결측값 처리</h4>
<h5 style="color: #008000">결측 데이터의 종류</h5>
1. 완전 무작위 결측(MCAR) : 관측된 혹은 관측되지 않은 다른 변수와 아무런 연관이 없는 경우
2. 무작위 결측(MAR) : 관측된 다른 변수와 연관되어 있지만 그 자체가 비관측값들과는 연관하지 않은 경우
3. 비무작위 결측(NMAR) : 어떤 변수의 결측 데이터가 완전 무작위 결측
<h5 style="color: #008000">결측값 유형의 분석 및 대치</h5>
1. 단순 대치법(Simple Imputation)
   - 완전 분석 : 불완전 자료는 완전하게 무시하고 분석을 수행
     용이성을 보장하나 효율성 상실과 통계적 추런의 타장성에 문제 발생 가능성이 있음
   - 평균 대치법 : 관측 또는 실험으로 얻어진 데이터의 평균으로 결측치를 대치하여 사용 통계량의 표준오차가 과소 추정되는 단점이 있음
   - 회귀 대치법 : 회귀분석에 의한 예측치로 결측치를 대체하는 방법으로 조건부 평균 대치법이라고도 한다.
   - 단순확률 대치법 : 평균 대치법에서 추정량 표준오차의 과소 추정을 보와하는 대치법으로 Hot-deck방법이라고도 함
   - 최근접 대치법 : 전체 표본을 몇 개의 대체군으로 분류하여 각 층에서의 응답자료를 순서대로 정리한 후 결측값 바로 이전의 응답을 결측치로 대치
2. 다중 대치법
   - 1단계 - 대치단계 : 복수의 대치에 의한 결측을 대치한 데이터를 생성
   - 2단계 - 분석단계 : 복수 개의 데이터셋에 대한 분석을 시행
   - 3단계 - 결합단계 : 복수 개의 분석결과에 대한 통계적 결합을 통해 결과를 도출
<h4 style="color: #FFFF00">데이터 이상값 처리</h4>
<h5 style="color: #008000">이상치의 종류 및 발생원인</h5>
1. 이상치의 종류
   - 단변수 이상치 : 하나의 데이터 분포에서 발생하는 이상치를 말한다.
   - 다변수 이상치 : 복수의 연결된 데이터 분포공간에서 발생하는 이상치를 의미한다.
2. 이상치의 발생 원인
   - 비자연적 이상치 발생 - 입력실수 / 측정오류 / 실험오류 / 의도적 이상치 / 자료처리오류 / 포본오류
<h5 style="color: #008000">이상치의 문제점</h5>
1. 기초 분석결과의 신뢰도 저하 - 평균, 분산 등에 영향을 줌
2. 기초 통계에 기반한 다른 고급 통계분석의 신뢰성 저하
<h5 style="color: #008000">이상치의 탐지</h5>
1. 시각화를 통한 방법
   - 상자 수염 그림
   - 줄기-잎 그림
   - 산점도 그림
2. Z-score 방법
3. 밀도기반 클러스터링 방법
4. 고립 의사나무 방법
   - 데이터 포인트 분할
   - 분할 기준 설정
   - 분할된 데이터 영역 계산
   - 이상치 탐지
   - 의사결정나무 생성
<h3 style="color: #FFA500">분석 변수 처리</h3>
<h4 style="color: #FFFF00">변수 선택</h4>
<h5 style="color: #008000">회귀분석의 사례</h5>
<h5 style="color: #008000">변수별 모형의 분류</h5>
1. 전체 모형
2. 축소 모형
3. 영 모형
<h5 style="color: #008000">변수의 선택 방법</h5>
1. 전진 선택법
2. 후진 선택법, 후진 소거법
3. 단계적 선택법
<h4 style="color: #FFFF00">차원 축소</h4>
<h5 style="color: #008000">자료의 차원</h5>
분석하는 데이터의 종류의 수를 의미
<h5 style="color: #008000">차원의 축소</h5>
목적에 따라서 변수의 양을 줄이는 것
<h5 style="color: #008000">차원 축소의 필요성</h5>
1. 복잡도의 축소
   동일한 품질을 나타낼 수 있다면 효율성 측면에서 데이터 종류 수를 줄여야 함
2. 과적합 방지
   적은 차원만으로 안정적인 결과를 도출해 낼 수 있다면 많은 차원을 다루는 것보다 효율적임
3. 해석력의 확보
   차원이 작은 간단한 분석모델일수록 내부구조 이해 용이 - 해석 용이
4. 차원의 저주
   차원이 증가하면서 학습데이터의 수가 차원의 수보다 적어져 성능이 저하되는 현상
   차원을 줄이거나 - 데이터의 수를 늘리는 방법을 이용
<h5 style="color: #008000">차원 축소의 방법</h5>
1. 요인분석
   - 변수 축소 - 정보손실을 억제하면서 소수의 요인으로 축약
   - 변수 제거 - 요인에 대한 중요도 파악
   - 변수특성 파악 - 군집으로서 요인간의 상호 독립성 파악이 용이해짐
   - 타당성 평가 - 묶여지지 않는 변수의 독립성 여부를 판단한다.
   - 파생변수 - 요인점수를 이용한 새로운 변수를 생성
2. 주성분 분석
   데이터들의 특성을 설명할 수 있는 하나 또는 복수 개의 특징을 찾는 것을 의미
   PCA는 데이터 하나하나에 대한 성분을 분석하는 것이 아니라, 여러 데이터들이 모여 하나의 분포를 이룰 때, 이 분포의 주성분을 분석해 주는 방법
3. 특이값 분해(SVD)
   데이터 공간 m x n 크기 행렬 M에 대해
   M = U(m x m 크기의 직교행렬) x ΣV^t(n x n 크기의 직교 행렬)
   직교행렬 : 행렬의 열벡터가 독립이라는 의미로 다음과 같은 관계가 성립
   대각행렬 : 행렬의 대각성분을 제외한 나머지행렬의 원소값이 모두 0인 행렬
   데이터 응용 : 큰 몇개의 특이값을 가지고도 충분히 유용한 정보를 유지할 수 있는 차원을 생성해 낼 수 있다.
4. 음수 미포함 행렬분해(NMF)
   음수 미포함 행렬분해는 음수를 포함하지 않은 행렬 V를 음수를 포함하지 않은 두 행렬의 곱으로 분해하는 알고리즘
   W(열개수)H(행개수) = V
<h4 style="color: #FFFF00">파생변수의 생성</h4>
<h5 style="color: #008000">파생변수</h5>
- 사용자가 특정 조건을 만족하거나 특정 함수에 의해 값을 만들어 의미를 부여하는 변수로 매우 주관적일 수 있으므로 논리적 타당성을 갖출 필요가 있음
- 세분화  고객행동예측, 캠페인반응예측 등에 활용할 수 있음
- 특정상황에만 유의미하지 않게 대표성을 나타나게 할 필요가 있음
<h5 style="color: #008000">요약변수</h5>
- 수집된 정보를 분석에 맞게 종합한 변수
- 데이터마트에서 가장 기본적인 변수
- 재활용성이 높음
<h5 style="color: #008000">요약변수 vs 파생변수</h5>
1. 요약변수 처리 유의점
   - 처리 방법에 따라 결측치의 처리 및 이상값 처리에 유의
   - 연속형 변수의 구간화 적용과 고정된 구간화를 통한 의미 파악시 정구간이 아닌 의미 있는 구간을 찾도록 해야함
2. 파생변수 생성 및 처리의 유의점
   - 보편적이고 전 데이터구간에 대표성을 가지는 파생변수 생성을 위해서 노력하여야함
   - 파생변수의 생성 방법
     한 값으로부터 특징을 추출
     한 레코드내의 값들을 결합
     다른 테이블의 부가적 정보를 결합한다.
     다수 필드내 시간 종속적인 데이터를 선택한다.
     레코드 또는 중요 필드를 요약
<h4 style="color: #FFFF00">변수 변환</h4>
<h5 style="color: #008000">변수 변환의 개념</h5>
데이터를 분석하기 좋은 형태로 바꾸는 작업
<h5 style="color: #008000">변수 변환의 방법</h5>
1. 범주형 변환
2. 정규화 - 상대적 특성이 반영된 데이터로 변환하는 것이 필요
   - 일반 정규화 : 수치로 된 값들을 여러 개 사용할 때 각 수치의 범위가 다르면 이를 같은 범위로 변환해서 사용
   - 최소-최대 정규화 : 데이터를 정규화하는 가장 일반적인 방법 최소값 0, 최대값 1, 다른값 0과 1 사이
   - Z-점수 정규화 : 이상치 문제를 피하는 데이터 정규화 전략
3. 로그변환
   - 로그변환분포를 사용하는 전형적 데이터
4. 역수변환
   그대로 사용하지 않고 역수를 사용하면 오히려 선형적 특성을 가지는 경우가 있음
   극단적인 좌측으로 치우친 경우 정규분포화를 위해 역수변환을 사용
5. 지수변환
   지수를 사용하면 오히려 선형적인 결과를 나타낼 경우가 있음
   데이터의 분포가 우측으로 치우친 경우 정규분포화를 위해 지수변환을 사용한다.
6. 제곱근변환
   제곱근을 사용하면 오히려 선형적인 특성을 가지는 경우
   데이터분포의 형태가 좌측으로 약간 치우친 경우 정규분포화를 위해 제곱근변환을 사용한다.
7. 분포형태별 정규분포로의 변환
   우로 치우침 - X^3
   우로 약간 치우침 - X^2
   좌로 치우침 - X^(1/2)
   좌로 치우침 - ln(X)
   극단적 좌로 치우침 - 1/X
8. Box-Cox
   데이터의 변환을 통해 정규분포에 가깝게 만들어 통계 분석 및 모델링을 용이하게 하는 통계적 방법
   ![[../../../../Pasted image 20230919231722.png]]
   여기서
   ![[../../../../Pasted image 20230919231826.png]]
   이므로 y(λ)는 모든 실수에서 연속인 변환
   - λ에 따라서 0일 때는 로그변환, 0이 아닐 때는 멱변환으로 변환된다.
<h4 style="color: #FFFF00">불균형 데이터 처리</h4>
데이터의 양에 차이가 큰 경우, 클래스 불균형이 있다고 말함
<h5 style="color: #008000">불균형 데이터의 문제점</h5>
너무 차이가 나면 단순히 우세한 클래스를 택하는 모형의 정확도가 높아지므로 모형의 성능판별이 어려워짐. 저오학도가 높아도 데이터 개수가 적은 클래스의 재현율이 급격히 작아지는 현상이 발생할 수 있음

<h5 style="color: #008000">불균형 데이터의 처리 방법</h5>
1. 가중치 균형방법
   loss를 계산할 때 특정 클래스의 데이터에 더 큰 loss 값을 갖도록 하는 방법
   - 고정 비율 이용 : 클래스의 비율에 따라 가중치를 두는 방법
   - 최적 비율 이용 : 분야와 최종 성능을 고려해 가중치 비율을 최적 세팅을 찾으면서 가중치를 찾아가는 방법
2. 언더샘플링과 오버샘플링
   비대칭 데이터는 다수 클래스 데이터에서 일부만 사용하는 언더샘플링이나, 소수 클래스 데이터를 증가시키는 오버샘플링을 사용하여 데이터 비율을 맞추면 정밀도가 향상됨
   - 언더샘플링
     대표클래스 일부만을 선택(대표성이 있어야함)하고, 소수클래스는 최대한 많은 데이터를 사용하는 방법
   - 오버샘플링
     소수클래스의 복사본을 만들어, 대표클래스의 수만큼 데이터를 만들어주는 것
<h4 style="color: #FFFF00">인코딩</h4>
<h5 style="color: #008000">레이블 인코딩</h5>
순서나 크기에 의미가 없는 범주형 데이터를 변환할 때 사용한다.
순서나 계층 구조가 없는 데이터에 주로 사용한다.
숫자값의 크기가 결과에 영향을 미칠 수 있으면 원-핫 인코딩과 같은 기법을 고려해야함
<h5 style="color: #008000">원-핫 인코딩</h5>
각 범주에 해당하는 인덱스만 1이고 나머지는 0인 이진 벡터로 변환
이를 통해 컴퓨터가 범주형 데이터를 이해하고 처리할 수 있음
<h5 style="color: #008000">타깃 인코딩</h5>
- 타깃 인코딩은 분류 문제에서 사용됨
- 수행단계 - 종속변수의 평균 값을 계산 / 계산된 평균 값을 해당 범주에 대한 인코딩 값으로 대체
- 과적합 가능성이 있으며, 훈련 데이터에만 적용되어야 함
  데이터가 적을경우 부적합할 가능성이 있음
<h2 style="color: #FF0000FF">데이터 탐색</h2>
<h3 style="color: #FFA500">데이터 탐색의 기초</h3>
<h4 style="color: #FFFF00">데이터 탐색의 개요</h4>
<h5 style="color: #008000">탐색적 데이터 분석(EDA)</h5>
다양한 방법을 통해 관찰하고 이해하는 과정을 의미하는 것으로 데이터 분석 전에 자료를 직관적인 방법으로 통찰하는 과정
<h5 style="color: #008000">탐색적 데이터 분석의 필요성</h5>
내제된 잠재적 문제에 대해 인식하고 해결안을 도출할 수 있음
<h5 style="color: #008000">분석과정 및 절차</h5>
- 분석 목적 변수 / 개별변수의 이름 설명
- 데이터 문제성을 확인 - 결측치 / 이상치
- 개별 속성값이 예상한 범위 분포를 가지는지 확인
- 관계속성 확인 절차를 가지는지 확인 상관관계 등
<h5 style="color: #008000">이상치 검출</h5>
이상치가 발생한 이유를 파악하는 것이 중요
1. 개별 데이터 관찰
   - 눈으로 보면 전체적인 추세와 특이사항 관찰
   - 많다고 앞부분만 보면 안되고 패턴이 뒤에 나타날 수도 있으므로 무작위 표본으로 추출하여 관찰
2. 통계값 활용
   - 적절한 요약 통계지표를 사용할 수 있음
   - 평균, 중앙값, 최빈값을 사용할 수 있음
   - 범위, 분산을 사용할 수 있음
   - 데이터의 특성에 주의해야함 이상값이 있을 때 평균에서는 영향있고 중앙값은 영향 없는 것 등
(μ+-2𝞼) or (μ+-1.5𝞼) 구간을 벗어나는 값을 이상치로 판단
𝞼 : 표준편차 μ : 평균
3. 시각화 활용
   시각적인 표현은 분석에 많은 도움을 준다.
   시각화를 통해 주어진 데이터의 개별 속성에 어던 통계 지표가 적절한지 결정할 수 있다.
4. 머신러닝 기법 활용
   대표적인 머신러닝 기법으로 K-means를 통해 이상치를 확인할 수 있다.
<h4 style="color: #FFFF00">상관관계분석</h4>
<h5 style="color: #008000">변수 간의 상관성 분석</h5>
1. 단순상관분석 - 두개의 변수가 어느정도 상관성이 있는지
2. 다중상관분석 - 3개 이상의 변수간의 관계강도를 측정
- 편상관관계분석 - 다중상관분석에서 다른 변수와의 관계를 고정하고 두 변수의 관계 강도를 측정하는 것
<h5 style="color: #008000">상관분석의 기본가정</h5>
1. 선형성
2. 동변량성 (등분산성)
3. 두 변인의 정규분포성
4. 무선독립표본
<h5 style="color: #008000">상관분석 방법</h5>
1. 피어슨 상관계수
   +1은 완벽한 양의 선형 상관관계, 0은 선형 상관관계없음, -1은 완벽한 음의 선형 상관관계
   ![[../../../../Pasted image 20230920001559.png]]
2. 스피어만 상관계수
   데이터가 서열자료인 경우, 값 대신 순위를 이용하는 경우
   두 변수간 연관 관계가 있는지 없는지를 밝혀줌 이상점이 있거나 표본크기가 작을 때 유용함
   ![[../../../../Pasted image 20230920002606.png]]
   크기 순으로 정한 두 변수의 차이가 클수록 스피어만 상관계수 값은 커짐
   스피어만 상관계수가 
   1에 가까울수록 단조적 상관성이 커짐
   0에 가까울수록 상관성이 없는 것으로 판단
<h4 style="color: #FFFF00">기초통계량의 추출 및 이해</h4>
<h5 style="color: #008000">중심화 경향 기초통계량</h5>
모평균 𝛍
표본평균 X^bar
기하평균
![[../../../../Pasted image 20230920003524.png]]
조화평균
![[../../../../Pasted image 20230920003612.png]]
중앙값 (Median)
최비값 (Mode)
분위수 (Quantile)
![[../../../../Pasted image 20230920003746.png]]
<h5 style="color: #008000">산점도 (분산도)</h5>
1. 분산 : 자료의 퍼짐정도나타내는 척도
2. 표준편차 : 분산으로 얻은 수치를 해석하기가 곤란하다는 단점을 보완하기 위해 제곱근을 취한 척도
3. 범위 : 데이터 간의 최댓값과 최솟값의 차이를 나타내는 것으로 동일한 범위를 갖더라도 자료의 분포모양은 다를 수가 있음에 유의해야 한다.
4. 평균 절대 편차 (MAD) : 각 자료값과 표본평균과의 편차의 절댓값에 대한 산술평균을 의미함
![[../../../../Pasted image 20230920004856.png]]
5. 사분범위 inter Quartile Range
	자료를 크기순으로 배열 후 자료의 각1/4에 해당하는 1사분위수 ~ 3사분위수(Q3)를 구하고
	사분위 범위는 Q3 - Q1로 정의 자료의 50% 범위 내에 위치하게 됨을 의미함
6. 변동계수 (CV)
   평균을 중심으로 한 상대적인 산포의 척도를 나타내는 수치
   측정 단위가 동일하지만 평균이 큰 차이를 보이는 두 자료집단 또는 측정단위가 서로 다른 두 자료집단에 대한 산포의 척도를 비교할 때 많이 사용
   ![[../../../../Pasted image 20230920005421.png]]
   변동계수가 클수록 상대적으로 넓게 분포를 이룲
<h5 style="color: #008000">자료의 분포형태</h5>
1. 왜도
   분포의 비대칭 정도를 나타내는 측도
   ![[../../../../Pasted image 20230920005622.png]]
   왜도 값은 일반적으로 -3 ~ +3 사이의 범위에 있고 
   왜도의 절댓값이 1.96보다 크면 비대칭성이 있다고 판단
2. 첨도
   분포의 뾰족한 정도
   ![[../../../../Pasted image 20230920005804.png]]
<h4 style="color: #FFFF00">시각적 데이터 탐색</h4>
<h5 style="color: #008000">통계적 시각화 도구</h5>
1. 도수분포표 : 도수 - 질적 자료의 경우 각 범주별 빈도 | 상대도수 - 도수/전체자료수
2. 히스토그램 : 도수분포표를 이용하여 표본의 자료분포를 나타낸 그래프
   히스토그램은 가로축에 반드시 수량을 표시하지만 막대그래프는 그렇지 아니함
3. 막대그래프 : 각 자료값에 대한 도수 또는 상대도수를 그림으로 표현한 것
4. 파이차트 : 각 자료값의 상대도수로 기입하여 원 면적에 각 상대 크기별로 나타낸 그래프
5. 산점도 : 직교 좌표계를 이용해 두 개 변수 간의 관계를 나타내는 방법
6. 줄기 잎 그림 : 통계적 자료를 표 형태와 그래프 형태의 혼합된 방법으로 나타내는 것을 말함 - 자료 정리 뿐 아니라 자료 구조에 대한 정보 파악가능
   - 작성절차
     크기순 정리 - 숫자 두 부분으로 나누어 앞부분은 줄기 뒷부분은 잎으로 나눔 - 줄기에 해당하는 숫자 크기순으로 나열 - 해당 줄기 우측 뒷부분에 잎 부분 기록
7. 상자 수염 그림
   자료로부터 얻어 낸 통계량 5가지 요약 수치(이상치, 최대값, 3사분위수, 중앙값, 1사분위수, 최소값)
   - 주어진 데이터에서 각 사분위수를 계산
   - 그래프에서 제1사분위와 제 3사분위를 밑변으로 하는 직사각형을 그리고, 제 2사분위에 해당하는 위치에 선분을 긋는다.
   - 사분위 범위(IQR : Q3-Q1)을 계산한다.
   - Q3과 차이가 1.5IQR 이내인 값 중 최댓갓ㅂ을 Q3과 직선으로 연결하고 마찬가지로 Q1과 차이가 1.5IQR 이내인 값 중에서 최솟값을 Q1과 연결한다.
   - Q3보다 1.5IQR 이상 초과하는 값과 Q1보다 1.5IQR 이상 미달하는 값은 점이나 원, 별표등으로 따로 표시한다. - 이상치 표시

<h3 style="color: #FFA500">고급 데이터 탐색</h3>
<h4 style="color: #FFFF00">시공간 데이터 탐색</h4>
<h5 style="color: #008000">시공간 데이터의 개념</h5>
- 공간적 정보에 시간의 흐름이 결합된 다차원 데이터
1. 시간데이터
   - 유효시간
   - 거래 시간
   - 사용자 정의 시간
   - 스냅샷 데이터
   - 거래 시간 데이터, 유효 시간 데이터
   - 이원 시간 데이터
2. 공간 데이터
   - 비공간 타입 - 기본적인 데이터 유형을 가진 속성
   - 래스터 공간 타입 : 실세계에 존재하는 객체의 이미지
   - 벡터 공간 타입 : 점, 선, 면 등의 요소로 구성
   - 기하학적 타입 : 벡터 타입의 요소로부터 거리, 면적, 길이 등과 같은 유클리드 기하학 계산 값으로 표현
   - 위상적 타입 : 공간 객체 간의 관계를 표현하며, 방위, 공간 객체 간의 중첩, 포함, 교차, 분리 등과 같은 위치적 관계로 대량의 공간을 필요로 해서 일반적으로 저장되지 않고 보통 공간객체로부터 동적으로 계산
3. 공간 데이터 모델
   - 관계형 모델 - 표현이 유연하지 못하고 실세계 공간의 객체의 특징을 적절히 표현하지 못하는 문제점이 있음
   - 객체지향 모델
     비 구조적 / 복잡한 데이터를 자연스럽게 표현
     계층 구조를 이용한 연산이 쉬움
     새로운 함수의 확장이 쉽다.
     데이터 무결성 검사가 쉽다.
     설계 단계 모델-구현 단계 모델 사이의 불일치 문제를 줄인다.
4. 시공간 데이터
   시간과 공간 데이터의 결합 형태를 지칭한다.
   - 실제 객체들은 공간적 정보 뿐만 아니라 시간적 정보와도 연관이 있음
     기본적으로 위치﹒영역과 같은 공간 정보는 시간의 흐름에 따라서 변화하기 때문임
<h5 style="color: #008000">시공간 데이터 분석</h5>
1. 시공간 데이터에 대한 질의어
   - 시공간자료 정의언어 : 시공간 테이블 인덱스 및 뷰의 정의문, 변경문 등이 포함
   - 시공간자료 조작언어 : 객체의 삽입, 삭제, 변경 등의 검색문이 있다. 시간지원 연산자와 공간 연산자를 포함하며 이를 통해 객체에 대한 공간관리와 이력정보를 제공
2. 시공간 데이터의 연산
   - 시공간위상 관계연산 - 두 객체 간 공간영역상의 관계에 대해 참﹒거짓을 반환하는 연산으로 대표적으로 교차 연산자는 선과 선의 교차, 선과 면의 교차 여부를 반환한다.
   - 시공간기하 연산 : 두 객체간의 거리 연산을 지칭
<h5 style="color: #008000">적용 및 응용분야</h5>
지리정보 시스템 / 위치기반 서비스 / 차량 위치추적 서비스 등에 활용됨
<h4 style="color: #FFFF00">다변량 데이터 탐색</h4>
<h5 style="color: #008000">종속변수와 독립변수 사이의 인과 관계</h5>
1. 다중회귀 (Multiple Regression)
   독립변수가 2개 이상인 회귀모형을 지칭하며 각 독립변수는 종속변수와 선형관계에 있음을 가정한다.
   - 장점
     분석내용의 질적인 향상 도모
     독립변수가 두개일 경우 : 모형 설정이 부정확할 경우와 중요한독립변수의 누락이 있을 수 있음 - 이는 편향(bias)를 야기시킬 수 있음
   - 일반형식
     ![[../../../../Pasted image 20230920143852.png]]
   - 기본가정
     회귀모형은 모수에 대해 선형인 모형
     오차항의 평균은 0이다.
     오차항의 분산은 모든 관찰치에 대해 일정한 분산을 갖는다.
     서로 다른 관찰치 간의 오차항은 상관이 없다.(오차항은 서로 독립이며 공분산은 0)
     오차항의 각 독립변수 역시 독립인 관계
     오차항은 정규분포를 따른다.
   - 분석방법
     최소자승법을 이용하여 결과를 도출할 수 있다.
2. 로지스틱 회귀 (Logistic Regression)
   사건의 발생 가능성을 예측하는데 사용되는 통계
   - 특징
     이항데이터에 적용하였을 때 종속변수 y의 결과가 범위 0,1로 제한된다는 것
     종송변수가 이진적이기 때문에 조건부 확률 P(y|x)의 분포가 정규분포 대신 이항 분포를 따른다는 점
     ![[../../../../Pasted image 20230920144356.png]]
3. 분산분석(ANOVA)
   3개 이상의 표본들의 차이를 표본평균 간의 분산과 표본 내의 관측간 분산을 비교하여 가설을 검정하는 것
   - 일원분산분석 : 단 하나의 인자에 근거하여 여러 수준으로 나누어지는 분석
   - 일원분산분석 특징 : 독립변수에 의해 종속변수에 대한 평균치의 차이를 검정하는데 이용
4. 다변량 분산분석
   측정형 변수, 종속변수가 2개 이상인 분산분석이다.
   - 이원분산분석 (Two-Way ANOVA) : 두개 이상의 인자에 근거하여 여러수준으로 나누어지는 분석
   - 이원분산분석 특징
     독립변인의 수가 둘
     한 변수에 따른 종속변수의 영향이 아니라 두 개 이상의 변수가 어떻게 차이가 나는가를 알아보고자 할 때 사용
<h5 style="color: #008000">공분산과 독립성 관계</h5>
한 변수의 변화가 다른 변수에 영향을 미치지 못하는 경우는 공분산이 0이 되지만
공분산이 0이라고 독립인 것이 아님 다른 종류의 관계가 있을 수 있음(이차항 관계, 상호작용 효과 등)
<h5 style="color: #008000">두 확률분포 간의 독립성 확인</h5>
1. 분포의 독립성 확인
   P(X*Y) = P(X) * P(Y)를 만족해야 한다.
2. 공분산 및 상관 계수 확인
   두 변수가 상호 독립이라면 공분산은 0이 되며 상관계수도 0이 된다.
3. 독립성 검정
   카이제곱 독립성 검정
<h5 style="color: #008000">변수축약</h5>
변수들 간의 상관관계를 이용하여 변수를 줄이는 방법으로 변수유도기법이라고도 한다.
1. 주성분 분석(PCA)
   - 다변량자료에서 존재하는 비정규성(abnormality)이나 이상치(outlier)를 발견하기 위하여 변수들의 상관관계가 존재하지 않는 새로운 변수를 구하는 것을 지칭함
   - 주성분 분석은 N개의 변수로부터 서로 독립인 K(N)개의 주성분을 구해 원 변수의 차원을 줄이는 방법이다.
2. 요인분석(Factor Analysis)
   상관관계를 분석하여 공통차원들을 통해 축약해 나가는 방법
   - 요인분석 특징
     독립변수와 종송변수 개념이 없음
     추론통계가 아닌 기술통계기법에 의해 수행이 가능함
   - 요인 분석의 목적
     변수 축소 : 여러개의 관련변수가 하나의 요인으로 묶임
     변수 제거 : 요인에 포함되지 않거나 포함되더라도 중요도가 낮은 변수를 찾을 수 있음
     변수 특성파악 : 변수들의 묶음으로 사오하 독립 특성을 파악하기 용이해짐
     측정항목의 타당성 평가 : 그룹이 되지 않은 변수의 특성을 구분할 수 있음
     요인점수를 통한 변수 생성 : 회귀분석, 군집분석, 판별분석 등에 적용 가능한 변수를 생성할 수 있음
3. 정준상관분석 (Canonical Analysis) Canonical - 표준(기준)이되는
   두 변수집단 간의 연관성을 각 변수집단에 속한 변수들의 선형결합의 상관계수를 이용하는 방법
   - 정준변수 (Canonical Variable) : 새로만들어진 선형결합
   - 정준상관계수 (Canonical Correlation Coefficient) : 정준변수들 사이의 상관계수이다.
   - 정준분석과 회귀분석의 차이점 : 회귀분석은 하나의 반응변수를 여러 개의 설명변수로 설명하고자 할 때, 가장 설명력이 높은 변수들의 선형결합을 찾아 이들 사이의 인과관계를 생각하는 반면에 정준분석에서는 이와같은 인과성이 없다.
<h5 style="color: #008000">개체유도</h5>
개체들의 특성을 측정한 변수들의 상관관계를 이용하여 유사한 개체를 분류하는 방법

1. 군집 분석(Cluster Analysis)
   모집단 또는 범주에 대한 사전정보가 없는 경우에 관측값들 사이의 거리를 이용하여 개체들을 자연스럽게 몇 개의 그룹 또는 군집으로 나누는 분석기법
   - 계층적 방법 : 가까운 개체끼리 차례로 묶거나 멀리 떨어진 개체를 차례로 분리해 가는 군집방법
   - 비계층적 방법 또는 최적분화 방법 : 다변량 자료의 산포를 나타내는 여러가지 측도를 이용하여 이들 판정기준을 최적화시키는 방법으로 군집을 나누는 방법 - 한번 분리된 개체도 반복적으로 시행하는 과정에서 재분류될 수 있는 것이 특징
   - 조밀도에 의한 방법 - 데이터가 분포한 특성에 따라 군집을 나누는 방법
   - 그래프를 이용한 방법 : 다차원 자료들을 2차원 또는 3차원으로 축소할 수 있다면 시각적 차원에서 자연스러운 군집을 형성할 수 있다.
2. 다차원 척도법
   다차원 척도법은 다차원 관측값 또는 개체들 간의 거리 또는 비유성을 이용하여 개체들을 원래의 차원보다 낮은 차원의 공간상에 위치시켜 개체들 사이의 구조 또는 관계를 쉽게 파악하고자 하는 데 목적이 있음
   - 차원의 축소와 개체들의 상대적 위치 등을 통해 개체들 사이의 관계를 쉽게 파악하고 공간적 배열에 대한 주관적인 해석에 중점을 두고 있다.
3. 판별분석
   2개 이상의  그룹으로 나누어진 개체에 대해 분류에 영향을 미칠 것 같은 특성을 측정하고 이를 이용하여 새로운 개체를 분류하는 방법이다.
   - 로지스틱 판별분석 : 분류를 하는 도구를 로지스틱 회귀분석을 이용하여 분류하는 방법
<h4 style="color: #FFFF00">비정형 데이터 탐색</h4>
<h5 style="color: #008000">비정형 데이터</h5>
비정형 데이터는 미리 정의된 데이터 모델이 없거나 미리 정의된 방식으로 정리되지 않은 정보를 말함
1. 특징
   - 일반적으로 텍스트 중심으로 되어 있고 날짜, 숫자, 사실과 같은 데이터도 포함되어 있음
   - 변칙과 모호함이 발생하므로 데이터베이스의 칸 형식의 폼에 저장되거나 문서에 주석화된 데이터에 비해 전통적인 프로그램을 사용하여 이해하는 것은 불가능하게 만든다.
2. 비정형 데이터 관리 및 분석 의미 도출
   - 정형 - 저장의 효율성 측면에서 정의된 규칙에 의해 저장 / 비정형 - 규격화의 어려움이 있어 저장 및 관리의 어려움이 있음
   - 차지하는 공간이 정형보다 넓다
   - 분석이 용이하지 않은 부분이 있다.
<h5 style="color: #008000">비정형 데이터의 분석</h5>
1. 데이터 마이닝
   대규모로 저장된 데이터 안에서 체계적이고 자동적으로 통계적 규칙이나 패턴을 분석하여 가치 있는 정보를 추출하는 과정
   - 데이터 마이닝은 통계학에서 패턴 인식에 이르는 다양한 계량 기법을 사용함
   - 데이터 마이닝 기법은 통계학 쪽에서 발전한 탐색적 자료분석, 가설검정, 다변량 분석, 시계열 분석, 일반선형모형 등의 방법론이 쓰임
   - 데이터베이스 쪽에서 발전한 OLAP(온라인 분석처리), 인공지능 진영에서 발전한 SOM, 신경망, 전문가 시스템 드으이 기술적인 방법론이 쓰인다.
   - 데이터 마이닝 적용 분야
     신용평점 시스템(Credit Scoring System) / 분류 / 군집화 / 연관성 / 연속성 / 예측
   - 데이터 마이닝의 단점
     자료에 의존하여 현상을 해석하고 개선하려고 하기 때문에 자료가 현실을 충분히 반영하지 못한 상태에서 정보를 추출한 모형을 개발할 경우 잘못된 모형을 구축하는 오류를 범할 수 있습니다.
2. 텍스트 마이닝(Text Mining)
   대규모 문서에서 정보 추출, 연계성 파악, 분류 및 군집화, 요약 등을 통해 데이터의 숨겨진 의미를 발견하는 기법
   - 자연어 처리(NLP)
3. 오피니언 마이닝(Opinion Mining)
   특정 주제에 대한 사람들의 주관적 의견을 통계﹒수치화해 객관적 정보로 바꾸는 빅데이터 분석기술이다.
   - 텍스트 마이닝은 문장 내 주제를 파악하고 오피니언 마이닝은 감정﹒뉘양스﹒태도 등을 판별하는 차이가 있음
   - 적용 분야
     특정 서비스 및 상품에 대한 시장 규모 예측, 소비자의 반응, 입소문 분석 등에 활용되고 있으며, 많은 기업이 자사와 자사 상품 관련 댓글﹒SNS 등을 실시간으로 분석해 이미지를 파악하고 대응 전략을 세워 사용하고 있다.
4. 웹 마이닝(Web Mining)
   웹 마이닝 또는 웹 데이터 마이닝은 일반적으로 웹 자원으로부터 의미있는 패턴, 추세 등을 도출해 내는 것을 지칭한다.
   - 웹마이닝 특징
     웹 환경에서 얻어지는 고객의 정보, 특정 행위, 패턴 등의 정보를 이용하여 다양한 활동에 활용할 수 있다.
     데이터 마이닝을 이용하여 문서들과  서비스로부터 정보를 추출할 수 있다.
     대량의 로그기록을 기반으로 정보를 수집하고 자료를 정제한다.
     웹상의 고객의 행동기록과 CRM 등을 연결하는 등 다양한 서비스에 접목이 가능하다.
   - 웹 마이닝의 유형
     웹구조 마이닝 : 웹 사이트로부터 구조적 요약정보를 추출하는 것이다.
     웹내용 마이닝 : 웹사이트 또는 페이지로부터 의미 있는 내용을 추출하는 것을 말한다.
     웹사용 마이닝 : 웹상의 사용자의 행동 등 패턴으로부터 통찰을 이끌어 내는 방법을 말한다.
<h2 style="color: #FF0000FF">통계기법 이해</h2>
<h3 style="color: #FFA500">기술통계</h3>
분석에 필요한 데이터를 요약하여 묘사 설명하는 통계기법을 말함
중심화 경향 / 분산도 경향 / 자료의 분포형태
<h4 style="color: #FFFF00">데이터 요약</h4>
데이터의 단순 정리가 아닌 데이터의 분포가 가지는 특성을 찾아내서 본격적인 분석 이전에 기본적인 특징을 수치적으로 정량화하여 기술한다
-주로 기초 통계량을 산출하여 결과를 도출함
<h4 style="color: #FFFF00">표본추출</h4>
모집단 / 표본 / 표본추출
<h5 style="color: #008000">전수조사와 표본조사</h5>
1. 전수조사 : 관심의 대상이 되는 모집단 전체를 조사하는 것
2. 표본조사 : 관심의 대상이 되는 모집단에서 표본을 추출하여 표본을 대상으로 조사를 시행하는 것
   일부의 표본으로 조사분석을 시행하고 모집단 전체의 분석결과로 사용이 가능
<h5 style="color: #008000">표본추출 오차</h5>
1. 과잉 대표 : 중복선택 등의 원인으로 모집단이 반복﹒중복된 데이터만으로 규정되는 현상
2. 최소 대표 : 실제모집단의 대표성을 나타낼 표본이 아닌 다른 데이터가 표본이 되는 현상
   - 표본추출 시 표본의 크기보다는 대표성을 가지는 표본을 추출하는 것이 중요하다.
<h5 style="color: #008000">확률 표본추출 기법</h5>
- 모든 표본들의 추출확률을 사전에 알 수 있다.
- 통계적 정확도를 확률적으로 나타낼 수 있다.
1. 단순무작위 추출(Simple Random Sampliing) : 통계조사에서 가장 기본이 되는 표본추출법임
   -추출모집단의 사전지식이 많지 않은 경우 시행하는 방법
2. 계통추출(Systematic Sampling) : 모집단에서 추출간격을 설정하여 간격 사이에서 무작위로 추출하는 방법 N개인 집단에서 K라는 추출간격으로 뽑음 K는 N보다 작아야함 N/K 수만큼의 표본이 선택될 수 있음
3. 층화추출
   모집단을 서로 겹치지 않게 여러 층으로 나누어 분할된 층별로 배정된 표본을 단순 임의 추출법에 따라 추출하는 방법이다.
   각 집단별 분석이 필요한 분석의 경우나 모집단 전체에 대한 특성치의 효율적 추정이 필요한 경우 시행한다.
   - 층화추출 특징
     -단순임의추출법에 비해 추정의 정도를 높일 수 있다.
     -전체 모집단의 추정뿐아니라 각층별 추정결과도 얻을 수 있다.
     -모집단을 효과적으로 층화할 경우 임의표본에서 구한 추정량보다 오차가 적게되어 추정의 정도를 높일 수 있다.
     -표본의 대표성 제고 및 조사관리가 편리하고, 조사비용이 절감된다.
   - 층화변수
     -모집단을 몇 개의 층으로 나누려고 할 때 각 추출단위가 어느 층에 속하는지를 구분하기 위해 기준으로 사용되는 변수
     -사전에 모집단 단위들의 정보를 쉽게 알 수 있으면서도 조사하고자 하는 주변수와 밀접한 관련이 있는 보조 변수가 되어야 한다.
     -질적 층화변수 : 변수값에 따라 층 구분
     -양적 층화변수 : 층의 경계점을 나누는 방법 필요
     양적 층화변수일 때 n개의 층으로 나누려면 n-1개의 경계점을 정해야함
     추정값의 분산을 최소화시킬 수 있도록 경계점 결정
   - 표본의 배분
     -각 층 내의 추출단위들의 수 : 많으면 크게 늘림
     -각 층 내에서 변동의 정도 : 변동의 정도가 커지면 크게 늘림
     -각 층에서 추출단위를 조사하는데 드는 비용 : 비용증가 시 줄임
4. 군집추출(Cluster Sampling)
   -모집단 차이가 없는 여러 개 군집으로 나누어 군집의 단위의 일부 도는 전체에 대한 분석을 시행한다.
   -모집단에 대한 구체적인 추출 방법론을 정하기 어려운 경우 사용하면 편리하다
   -표본크기가 같은 경우 단순 임의추출에 비해 표본 오차가 증대할 가능성이 있다.
<h5 style="color: #008000">비확률 표본추출 기법</h5>
각 추출단위들이 표본에 추출될 확률을 객관적으로 나타낼 수 없는 표본추출법이다.
일반적으로 모집단을 정확하게 규정지을 수 없는 경우
표본오차가 큰 문제가 되지 않는경우
새로운 개념에 대한 탐색적 연구 등에 사용
비용, 시간, 조사의 편리함 때문에 자주 사용한다.
1. 간편추출법(편의추출법, Convenience Sampling)
   - 응답자를 선정하는 데 있어서 조사원 개인의 자의적인 판단에 따라 간편한 방법으로 표본을 추출하는 방법
   - 얻어진 표본이 목표모집단을 얼마나 잘 대표하는지 알 수 없고, 얻어진 통계치에 대한 통계적 정확성을 평가할 수 없다.
2. 판단추출법(Judgement Sampling)
   - 조사자가 나르므이 지식과 경험에 의해 모집단을 가장 잘 대표한다고 여겨지는 표본을 주관적으로 선정하는 방법
   - 조사자의 주간적 판단이 들어가기 때문에 추정치의 정확성에 대해 객관적으로 평가할 수 없다.
   - 표본의 크기가 작은 경우에 조사의 오차를 좌우하는 요인은 추정량의 분산이 될 수 있다.
3. 할당추출법(Quota Sampling)
   - 조사목적과 밀접하게 관련되어 있는 조사대상자의 연령이나 성별과 같은 변수 값에 따라 모집단을 부분집단으로 구분하고, 모집단의 부분집단별 구성비율과 표본의 부분집단별 구성비율이 유사하도록 표본을 선정하는 방법
   - 비용이 적게 들고 손쉽기 때문에 단기간에 조사를 해야하는 경우에 알맞은 방법이다.
4. 눈덩이 추출법(Snowball Sampling)
   - 접근이 어렵거나 추출틀의 작성이 곤란한 특정한 집단에 대한 조사에서 사용되는 방식
   - 먼저 해당 집단에 속하는 것을 사전에 알고 있는 사람들을 대상으로, 해당 집단에 속하는 다른 사람들을 소개받아서 조사를 진행하는 방법
<h4 style="color: #FFFF00">확률분포</h4>
- 기술통계 : 분석에 필요한 데이터를 요약하고 묘사﹒설명하는 통계기법이다.
- 추측(추론)통계 : 표본에 내포되어 있는 정보를 이용하여 모집단에 대한 과학적인 추론을 하는 통계기법
<h5 style="color: #008000">확률의 개념</h5>
- 통계적 현상 : 불확정 현상을 반복하여 관찰하거나 혹은 집단 안에서 대량으로 관찰하여 그 고유의 법칙성을 찾아내는 것이 가능한 현상을 지칭
- 확률 실험 : 같은 조건 아래에서 반복할 수 있다. 새행의 결과는 매번 우연적으로 변하므로 예측할 수 없으나 가능한 모든 결과의 집합을 알 수 있다. 시행을 반복할 때 낱낱의 결과는 불규칙하게 나타나지만, 반복의 수를 늘리면 어떤 규칙성이 나타나는 특징을 가질 수 있다.
![[Pasted image 20230920191444.png]]
![[Pasted image 20230920191456.png]]
1. 확률
   통계적 현상의 확실함의 정도
   - 수학적 확률(Mathematical Probability)
     ![[Pasted image 20230920191623.png]]
   - 통계적 확률 (Statistical Probability) : 사건이 일어나는 확률을 상대도수에 의해 추정
     ![[Pasted image 20230920192024.png]]
2. 사건(Event)
   동일한 상태로 여러 차례 반복할 수 있는 실험이나 관측을 시행이라 하고, 시행의 결과로서 나타나는 것을 사건이라 한다.
3. 표본공간(Sample Space)
   - 통계적 실험에서 모든 발생 가능한 실험결과들의 집합
   - 표본공간 자체는 전사건, 아무것도 포함하지 않는 사건은 공사건이라 하고 하나의 결과를 포함하는 사건은 근원사건이라고 한다.
   - 표본공간이 S인 확률 실험에서 사건은 S의 부분집합이 된다.
4. 확률의 기본성질
   정리1. 사건 A가 발생할 확률은 항상 0 이상이다.
   정리2. 표본공간S 사건이 발생할 확률은 1이다.
   정리3. ![[Pasted image 20230920192545.png]]
   정리4. ![[Pasted image 20230920192620.png]]
   정리5. 존재하지 않는 사건이 일어날 확률은 0이다.
   정리6. ![[Pasted image 20230920192735.png]]
5. 조건부 확률
   ![[Pasted image 20230920192824.png]]
   베이지안 정리와 결합해서 알아둬야함
6. 결합 확률(확률의 곱셈)
   사건A와 사건B가 동시에 발생하는 확률
   ![[Pasted image 20230920193109.png]]
7. 총확률정리(Total Probability Rule)
   임의의 사건 B의 확률 k개의 조건부 확률을 이용해서 구하는 것이다.
   사전에 표본공간은 상호 배타적인(i와 j가 다르면 Ai와 Aj의 교집합은 공집합인 관계) 사건으로 분할(partition)적인 사건으로 분할되었다고 하면 임의의 사건 P(B)는 아래와 같이 표현이 가능함
   ![[Pasted image 20230920193732.png]]
8. 베이지안 정리(Baye's Theorem)
   총확률정리를 이용하여 임의의 사건 B의 확률을 k개의 조건부 확률을 이용해 계산하면 베이지안 법칙을 이용하여 표본공간을 분할하는 k개의 상호 배타적인 사건에 대ㅏ한 사후 확률
   P(Ai)는 미리 주어진 사전확률(Prior Probability)이지만 사건 B라는 새로운 사건이 발생 시 P(Ai|B)의 확률을 구할 수 있고 이 확률이 사후 확률이 됨
   ![[Pasted image 20230920195349.png]]
<h5 style="color: #008000">확률변수</h5>
1. 확률변수(Random Variable)
   사건의 시행의 결과를 하나의 수치로 대응시킬 때의 값(확률값)
   일반적으로 대문자 X를 사용
2. 확률변수의 종류
   - 이산확률변수(Discrete Random Variable) : 확률변수가 취할 수 있는 값의 수가 유한한 변수
   - 연속확률변수(Continuous Random Variable) : 확률변수가 취할 수 있는 값의 수가 무한한 변수이다.
<h5 style="color: #008000">확률분포</h5>
확률분포는 수치로 대응된 확률변수의 개별 값들이 가지는 확률값의 분포
1. 이산확률분포
   - 확률질량함수(Probabiliyt Mass Function) : 이산확률변수에서 특정값에 대한 확률을 나타내는 함수
     ![[Pasted image 20230920201036.png]]
2. 연속확률분포
   - 확률밀도함수(Probability Density Function) : 확률 변수의 분포를 나타내는 함수이다.
     ![[Pasted image 20230920201246.png]]
3. 확률분포함수
   - 이산확률분포함수 : 확률변수가 이산적인 확률분포를 가지는 함수
   - 연속확률분포함수 : 확률변수가 연속적인 확률분포를 가지는 함수
<h5 style="color: #008000">확률변수의 기댓값과 분산</h5>
1. 기댓값(Expected Value)
   - 이산확률변수의 기댓값
     ![[Pasted image 20230920201540.png]]
   - 연속확률변수의 기댓값
     ![[Pasted image 20230920201745.png]]
2. 기댓값의 성질
   ![[Pasted image 20230920201949.png]]
3. 분산
   산포도를 나타내는 측도로 기댓값에서 떨어진 거리의 제곱의 기댓값이며 Var(X)로 표시
   - 이산확률변수의 분산
     ![[Pasted image 20230920202851.png]]
   - 연속확률변수의 분산
     ![[Pasted image 20230920203042.png]]
4. 분산의 성질
   ![[Pasted image 20230920203205.png]]
<h5 style="color: #008000">이상확률분포의 종류</h5>
1. 베르누이분포
   결과가 성공 아니면 실패
   ![[Pasted image 20230920203917.png]]
2. 이항분포
   ![[Pasted image 20230920204047.png]]
3. 다항분포
   ![[Pasted image 20230920205559.png]]
4. 포아송분포(Poisson Distribution)
   단위 시간 안에 어떤 사건이 몇 번 발생할 것인지를 표현하는 이산확률분포이다.
   ex) 은행창구에 도착한 고객의 수, 책 한 페이지당 오탈자의 수 등
   ![[Pasted image 20230920234915.png]]
   포아송분포의 근사 : X는 n이 무한히 커지고 성공화률 p가 매우 작다면(n>=30, p<=0.05)
   λ=np(이항분포의 기댓값)으로 될 수 있고 포아송분포를 따른다.
5. 기하분포(Geometric Distribution)
   베르누이 시행에서 처음 성공까지 시도한 횟수를 분포화한 이산확률분포의 한 종류
   ![[Pasted image 20230920235316.png]]
6. 음이항분포(Negative Binomial Distribution)
   x번의 베르누이 시행에서 k번째 성공할 때까지 계속 시행하는 실험에서의 확률을 나타내는 이산확률분포이다. 전체 x번의 시행에서 생각해보면 x-1까지 k-1개의 성공이 있어야함
   ![[Pasted image 20230920235938.png]]
7. 초기하분포(Hypergeometric Distribution)
   비복원 추출에서 N개 중에 n개를 추출했을 때, 원하는 것 k개가 뽑힐 확률을 나타내는 이산확률분포이다.
   ![[Pasted image 20230921001641.png]]
<h5 style="color: #008000">연속확률분포 종류</h5>
1. 연속균등분포(Continuous Uniform Distribution)
   a,b 범위에서 균등한 확률을 가진다.
   ![[Pasted image 20230921002041.png]]
2. 지수분포(Exponential Distribution)
   사건이 서로 독립적일 때, 일정한 시간 동안 발생하는 사건의 횟수가 포아송분포를 따르면, 다음 사건이 일어날 때까지의 대기시간에 대한 확률이 따르는 분포이다.
   포아송과정에서 한 개의 사건이 발생할 때까지의 대기 시간을 의미
   ![[Pasted image 20230921002359.png]]
   - 지수분포의 특징
     -포아송분포와의 관계 : 단위 시간당 발생하는 사건의 횟수를 관측. 반면 지수분포는 사건이 일어날 때까지의 대기 시간을 관측하는데 관심이 있는 것임-지수분포는 대기시간, 포아송분포는 횟수-
     -지수분포의 무기억성질(Memoryless Property)
     X~Exp(𝛽)일 때 어떤 수 a, b에 대해
     ![[Pasted image 20230921002652.png]]
     이 성질을 지수분포의 무기억성질이라 한다.
     좌변을 고려시 이전의 a에 대한 확률값은 고려대상이 안되고 결국 우변인 P(X>b)만 고려하면 된다는 의미
3. 정규분포(Normal Distribution)
   표본을 통한 통계적 추정 및 가설검정이론의 핵심이 되며 실제로 우리가 사회적, 자연적 현상에서 잡하는 여러 자료들의 분포가 정규분포를 띠게 된다.
   ![[Pasted image 20230921003009.png]]
   - 정규분포 특징
     -정규분포는 평균을 중심으로 대칭이며 종모양인 확률밀도함수의 그래프를 띤다.
4. 표준정규분포(Standard Normal Distribution)
   표준정규분포는 평균 𝛍=0, 표준편차 𝞼=1이 되도록 표준호한 정규분포이다.
   - 정규화 : X의 값이 그 분포의 평균에서 표준편차 대비 얼마나 떨어져 있는지를 표준화된 정규분포 변환식에 의해서 알 수 있다.
     ![[Pasted image 20230921004202.png]]
5. 감마분포(Gamma Distribution)
   두개의 매개변수를 받으며 양의 실수를 가질 수 있다. 매개변수와 연관이 있는 분포로 포아송과정에서 k개의 사건이 발생할 때까지의 대기시간으로 확률변수 X를 정의할 수 있다.
   ![[Pasted image 20230921010146.png]]
   - 감마분포의 특징
     (k, 𝝷)=(1,𝝷) 경우의 감마분포는 지수분포와 동일하다.
     신뢰성 이론이나 수명시험에 유용하게 사용됨
   - 카이제곱분포
     k개의 서로 독립적인 표준정규확률 변수를 각각 제곱한 다음 합해서 얻어지는 분포로 정의양의 정수 k가 주어졌을 때, k개의 독립적이고 표준 정규분포를 따르는 확률변수 X1, ... , Xk를 정의하면 k의 카이제곱분포는 W=ΣXi^2를 확률변수로 가지는 분포이다.
     ![[Pasted image 20230921011053.png]]
     카이제곱 분포는 신뢰구간이나 가설 검정에서 많이 사용된다.
6. 스튜던트 t분포(X~t(n-1))
   정규분포의 평균 측정 시 주로 사용하는 분포이다. 분포의 모양은 Z-분포와 유사하다.
   자유도 : 표본 크기 n에서 1을 뺀 것
   ![[Pasted image 20230921011518.png]]
7. F분포(F Distribution, X~F(k1, k2))
   두 개의 확률 변수 V1, V2의 자유도가 각각 k1, k2이고 서로 카이제곱분포를 따른다고 할 때 다음과 같이 정의된 확률변수
   ![[Pasted image 20230921011710.png]]
   자유도가 k1, k2인 F-분포를 따른다고 함
   <h4 style="color: #FFFF00">표본분포</h4>
<h5 style="color: #008000">모집단 분포와 표본분포</h5>
1. 모집단의 모수
   모집단의 평균 𝛍, 모집단의 표준편차 𝞼
2. 표본의 통계량
   표본집단의 평균 Xbar, 표본집단의 표준편차 S
<h5 style="color: #008000">표본평균의 표본분포</h5>
모집단으로부터 표본을 추출하였을 때 얻을 수 있는 모든 표본평균값을 확률변수로 하는 확률분포이다.
<h5 style="color: #008000">표본평균의 표본분포 통계량</h5>
1/nE(Σxi)
모집단의 평균과 같으므로 𝛍
표본분산은 𝞼^2/n
표준오차 ![[../../../../Pasted image 20230921013937.png]]
<h5 style="color: #008000">중심극한정리</h5>
1. 린데베르그-레비 중심극한 정리
   ![[Pasted image 20230921014202.png]]
2. 중심극한정리의 의미
   모집단 분포가 무엇이든 사오간업시 표본 수가큰 표본분포들의 표본평균의 분포가 정규분포를 이룬다는 의미
   -표본크기가 충분히 크다는 조건은 일반적으로 30이상이 있다.
<h5 style="color: #008000">표본평균의 표준화</h5>
![[../../../../Pasted image 20230921014516.png]]
- 표준화 Z는 확률변수인 표본평균을 모평균인 𝛍로부터 표본평균들의 표준편차인 표준오차의 몇배만큼 떨어져 있는가를 표시하는 것
  ![[Pasted image 20230921014742.png]]
  표본평균의 구간 확률
  표본평균을 표준화한 후 표준정규분포표를 이용하여 확률을 찾으면 된다.
<h5 style="color: #008000">표본비율</h5>
n개의 개체 중에서 성공으로 나타나는 개체 수의 비율을 표본비율 P(hat)=X/n
<h5 style="color: #008000">표본비율의 표본분포</h5>
표본으로 추출될 가능성이 있는 모든 표본들에 대한 표본비율 값의 확률분포를 표본비율의 표본분포라고 한다.
1. 표본분포에서의 평균과 표준오차
   ![[Pasted image 20230921015027.png]]
2. 표본비율의 표본분포
   표본비율의 표준화는 표본평균의 표준화와 동일개념이다.![[Pasted image 20230921015145.png]]
### 추론통계
# 빅데이터 모델링
## <mark style="color: #FF0000FF">분석 모형 설계</mark>
### 분석 절차 수립
### 분석 환경 구축
## <mark style="color: #FF0000FF">분석기법 적용</mark>
### 분석기법
### 고급 분석기법
# 빅데이터 결과 해석
## <mark style="color: #FF0000FF">분석 모형 평가 및 개선</mark>
### 분석 모형 평가
### 분석 모형 개선
## <mark style="color: #FF0000FF">분석결과 해석 및 활용</mark>
### 분석결과 해석
### 분석결과 시각화
### 분석결과 활용
